{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import yaml\n",
    "with open(\"config.yaml\", \"r\") as fh:\n",
    "    config_dict = yaml.safe_load(fh)['default']\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls /nfs/nas22/fs2202/biol_micro_bioinf_nccr/hardt/nguyenb/tnseq/scratch/03_23_transcriptomics/modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(config_dict[\"root\"])\n",
    "synth_dir = root/config_dict[\"synth_dir\"]\n",
    "sample_data_file = root/config_dict[\"sample_data_file\"]\n",
    "spikes = pd.read_table(synth_dir/\"synth_mgx_mtx/true-exp.mtx_spiked.tsv\", header=None, names=['feature', 'positive'])\n",
    "spikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving synthetic data in the format accepted by deseq2. \n",
    "- Added 1 because with such low 'depth' DESeq2 fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "dsdf = pd.read_table(synth_dir/\"synth_mgx_mtx/true-exp.mtx_abunds.tsv\", index_col=0).T.reset_index().rename(columns={'index': 'sample_id'})\n",
    "ds_meta = dsdf[['sample_id', 'Phenotype']]\n",
    "dsdf = dsdf.drop(columns=['Phenotype', 'SeqDepth']).set_index('sample_id').T.reset_index().rename(columns={'#':'ID'}).set_index('ID')\n",
    "dsdf = dsdf + 1\n",
    "#ds_meta.to_csv(synth_dir/'true-exp-meta.csv', index=False)\n",
    "#dsdf.reset_index().to_csv(synth_dir/\"true-exp-counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESeq results on all samples with 1 added to all counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analysis with global normalisation\n",
    "deres = pd.read_csv(synth_dir/\"2023-07-31_true-exp-deseq-1_vs_0_l0a0.01_results.csv\")\n",
    "deres = deres.merge(spikes, left_on='ID', right_on='feature', how='outer')\n",
    "# Analysis with taxon specific normalisation\n",
    "deres_tx = pd.read_csv(synth_dir/\"2023-07-31_true-exp-deseq-within-taxon-1_vs_0_l0a0.01_results.csv\")\n",
    "deres_tx = deres_tx.merge(spikes, left_on='ID', right_on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr = 0.01\n",
    "predicted = (deres.padj < fdr).astype(int)\n",
    "actual = (deres.positive.notnull()).astype(int)\n",
    "predicted_tx = (deres_tx.padj < fdr).astype(int)\n",
    "actual_tx = (deres_tx.positive.notnull()).astype(int)\n",
    "deseq_all = [precision_score(actual, predicted), recall_score(actual, predicted)] + list(confusion_matrix(actual, predicted).ravel().astype(int))\n",
    "deseq_tx = [precision_score(actual_tx, predicted_tx), recall_score(actual_tx, predicted_tx)] + list(confusion_matrix(actual_tx, predicted_tx).ravel().astype(int))\n",
    "labels = ['Precision', 'Recall', 'TN', 'FP', 'FN', 'TP']\n",
    "bench_df = pd.DataFrame([deseq_all, deseq_tx], columns=labels, index = ['Global', 'Taxon']).apply(round,ndigits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same analysis with linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(synth_dir/\"synth_mgx_mtx/true-exp.mtx_abunds.tsv\", index_col=0).T.reset_index().rename(columns={'index': 'sample_id'})\n",
    "df = df.melt(id_vars=[\"sample_id\", \"Phenotype\", \"SeqDepth\"], var_name=\"gene_name\", value_name='raw_cnt')\n",
    "df['tss'] = df['raw_cnt']/df['SeqDepth']*1e6\n",
    "df['bug'] = df['gene_name'].str.split(\"_\", expand=True)[0]\n",
    "df = df.merge(df.groupby(['sample_id', 'bug']).raw_cnt.sum().reset_index().rename(columns={'raw_cnt':'bug_cnt'}), on=['sample_id', 'bug'], how='left')\n",
    "df['within_bug'] = df['raw_cnt']/df['bug_cnt']*1e6\n",
    "df['bug_perc'] = df['bug_cnt']/df['SeqDepth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sample_id == 'SAMPLE0001'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gene = \"BUG0007_GROUP001780\"\n",
    "df[df.gene_name == test_gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out genes with less than 100 reads across samples\n",
    "mask = df.groupby(['gene_name']).raw_cnt.sum() > 100\n",
    "mask2 = df[df.raw_cnt > 0].groupby('gene_name').sample_id.nunique() > 10\n",
    "df_filtered = df.set_index('gene_name').loc[mask&mask2,:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df = df[df.gene_name == test_gene].copy()\n",
    "def linear_on_gene(gene_df, expr_col, fixed_effects):\n",
    "    pseudo_count = gene_df[gene_df[expr_col] > 0][expr_col].min()/2\n",
    "    gene_df[f'{expr_col}_log'] = np.log10(gene_df[expr_col] + pseudo_count)\n",
    "    #gene_df['tss_log_std'] = (gene_df['tss_log'] - gene_df['tss_log'].mean())/gene_df['tss_log'].std()\n",
    "    if not gene_df.empty and any([i in gene_df.columns for i in fixed_effects]):\n",
    "        formula = f\"{expr_col}_log ~ {' + '.join(fixed_effects)}\"\n",
    "        #print(formula)\n",
    "        md = smf.glm(formula=formula, data=gene_df, family=sm.families.Gaussian()).fit()\n",
    "        #print(md.summary())\n",
    "        return [md.params[1], md.bse[1], md.pvalues[1]]\n",
    "    return []\n",
    "\n",
    "def linear_on_df(df, expr_col, fixed_effects):\n",
    "    f = df.dropna().groupby('gene_name').apply(linear_on_gene, expr_col = expr_col, fixed_effects = fixed_effects).reset_index()\n",
    "    f[['coef', 'se', 'pval']] = pd.DataFrame(f[0].to_list(), index = f.index)\n",
    "    f = f.drop(columns=[0])\n",
    "    f['padj'] = statsmodels.stats.multitest.multipletests(f.pval.values, method='fdr_bh')[1]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_tx = linear_on_df(df_filtered, 'within_bug', ['Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(result_df, ground_truth, left_feat, right_feat, name, fdr=0.05):\n",
    "    df = result_df[[left_feat, 'padj']].merge(ground_truth, left_on=left_feat, right_on=right_feat, how='outer')\n",
    "    predicted_phenotype_tx = (df.padj < fdr).astype(int)\n",
    "    actual_phenotype_tx = (df.positive.notnull()).astype(int)\n",
    "    return  pd.Series([precision_score(actual_phenotype_tx, predicted_phenotype_tx), \n",
    "                       recall_score(actual_phenotype_tx, predicted_phenotype_tx)] + list(confusion_matrix(actual_phenotype_tx, predicted_phenotype_tx).ravel().astype(int)),index=['Precision', 'Recall', 'TN', 'FP', 'FN', 'TP'], name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(phenotype_tx, spikes, 'gene_name', 'feature', 'linear-phenotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_bug_tx = linear_on_df(df_filtered, 'within_bug', ['Phenotype', 'bug_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(phenotype_bug_tx, spikes, 'gene_name', 'feature', 'linear-bug-phenotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_global = linear_on_df(df_filtered, 'tss', ['Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(phenotype_global, spikes, 'gene_name', 'feature', 'linear-bug-phenotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_on_gene(gene_df, 'within_bug', ['Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_filtered[df_filtered.gene_name.isin(test_genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = linear_on_df(df_filtered, 'tss', ['Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby('bug').bug_cnt.median().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.merge(spikes, left_on='gene_name', right_on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = linear_on_df(df_filtered, 'within_bug', ['Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res2.merge(spikes, left_on='gene_name', right_on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2[res2.padj < 0.05].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "121/2085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2[res2.padj < 0.05].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = linear_on_df(df_filtered, 'within_bug', ['Phenotype', 'bug_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4 = linear_on_df(df_filtered, 'within_bug', ['Phenotype', 'bug_perc', 'bug_perc*Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4 = res4.merge(spikes, left_on='gene_name', right_on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4['gene_name'] = res4['gene_name'].fillna(res4.feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7 = res4[res4.gene_name.str.contains('BUG0007')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7[(b7.positive.notnull()) & (b7.padj < 0.05)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4[res4.padj < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = res3.merge(spikes, left_on='gene_name', right_on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3.dropna(subset=['gene_name'])[~res3.positive.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2000/6818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3[res3.padj < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "statsmodels.stats.multitest.multipletests(f.pval.values, method='fdr_bh')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.dropna().groupby('gene_name').apply(linear_on_gene, expr_col = 'within_bug', fixed_effects = ['Phenotype', 'bug_perc', 'Phenotype*bug_perc']).reset_index()\n",
    "y = test.dropna().groupby('gene_name').apply(linear_on_gene, expr_col = 'within_bug', fixed_effects = ['Phenotype']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' + '.join(['Phenotype', 'bug_perc', 'Phenotype*bug_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][3].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][3].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_on_gene(test, 'within', ['Phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(gene_df, x=\"Phenotype\", y='tss_log_std', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run linear model\n",
    "# md = smf.ols(formula=\"tss_log ~ Phenotype\", data=test_df)\n",
    "# mdf = md.fit()\n",
    "# mdf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear model\n",
    "md = smf.glm(formula=\"tss_log_std ~ Phenotype\", data=gene_df, family=sm.families.Gaussian())\n",
    "mdf = md.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.bse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from re-running mtx package\n",
    "res = pd.read_table(\"../test_out/all_results.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.merge(spikes, on='feature', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[(~res.positive.isna()) & (res.qval < 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results for M1 model for this dataset\n",
    "m1_res = pd.read_table(data_dir/\"strict_filtering/true-exp_RNA/all_results.fdr_correction.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_res[m1_res.feature.str.contains(test_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_res.sort_values(['coef', 'qval'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data= df[['sample_id', 'Phenotype', 'SeqDepth']]\n",
    "count_data = df[['sample_id'] + [c for c in df.columns if 'BUG' in c]].set_index('sample_id').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.to_csv(data_dir/\"true-exp.mtx_abunds_meta.csv\",  index=False)\n",
    "count_data.to_csv(data_dir/\"true-exp.mtx_abunds_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df = pd.read_table(data_dir/\"true-exp.bug_abunds.tsv\").iloc[2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df.to_csv(data_dir/\"true-exp.bug_abunds_edited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "res = pd.read_table('../test_out/all_results.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res.qval < 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = pd.read_table(data_dir/\"true-exp.mtx_spiked.tsv\", header=None, names=['feature', 'positive'])\n",
    "spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.merge(spikes, on ='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[(res.qval < 0.25) & (res.positive == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.positive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_res = pd.read_table(\"/nfs/nas22/fs2202/biol_micro_bioinf_nccr/hardt/nguyenb/tnseq/scratch/03_23_transcriptomics/modeling/strict_filtering/true-exp_mtx_vs_bug/all_results.fdr_correction.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values('qval').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = res.merge(pub_res, on='feature', suffixes=[\"_me\", \"_pub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSS within each bug \n",
    "# BUG abundances based on TX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = count_data.reset_index().rename(columns={'#': 'gene_name'}).copy()\n",
    "cdf['bug'] = cdf.gene_name.str.split(\"_\", expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = cdf.melt(id_vars=['gene_name', 'bug'], var_name='sample_id', value_name='cnts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = cdf.groupby(['sample_id', 'bug']).cnts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_tx_abund = (sm/sm.groupby(level=0).transform('sum') * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_tx_abund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sm.reset_index()\n",
    "sm.columns = ['sample_id', 'bug', 'bug_ab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = cdf.merge(sm, on=['sample_id', 'bug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['tx_cnts'] = cdf['cnts']/cdf['bug_ab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.pivot(index='gene_name', columns='sample_id', values='tx_cnts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= cdf[cdf.gene_name == 'BUG0007_GROUP000391']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.tx_cnts>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(meta_data, on='sample_id')\n",
    "test = test.merge(bug_tx_abund, on=['sample_id', 'bug'], suffixes=['_raw', '_bug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula='tx_cnts ~ Phenotype + bug_ab', data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sm.datasets.get_rdataset(\"dietox\", \"geepack\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datavis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
