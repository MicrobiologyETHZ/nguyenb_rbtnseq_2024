{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.stats import ranksums\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio\n",
    "import chart_studio.tools as tls\n",
    "import chart_studio.plotly as py\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import cufflinks as cf\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "import dash_bio as dashbio\n",
    "import os\n",
    "\n",
    "from quality_control import *\n",
    "from method1_analysis import *\n",
    "from method2_analysis import *\n",
    "from final_analysis import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-expansion",
   "metadata": {},
   "source": [
    "# Table of Contents: <a id='start'></a>\n",
    "\n",
    "1. [Loading the data](#loading-data)\n",
    "2. [Filtering the data](#filtering)\n",
    "2. [Method 1](#Method-1)\n",
    "3. [Method 2](#Method-2)\n",
    "4. [Compare the results](#Compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-pressure",
   "metadata": {},
   "source": [
    "# Loading the data <a id='loading-data'></a>\n",
    "\n",
    "\n",
    "## Data Analysed:\n",
    "\n",
    "List of dnaids\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Todo: move file directories to config files, so that can be re-run with different counts\n",
    "\n",
    "counts_dir =\"/Users/ansintsova/git_repos/nguyenb_tnseq/data/13_04_results/counts\"\n",
    "outdir = '/Users/ansintsova/git_repos/nguyenb_tnseq/data/07_06_results/'\n",
    "control_file = Path(\"/Users/ansintsova/git_repos/nguyenb_tnseq/data/13_04_results\")/'controls.txt'\n",
    "\n",
    "# Load\n",
    "dnaids = ['dnaid1315', 'dnaid1428', 'dnaid1429', 'dnaid1457', 'dnaid2015', 'dnaid2016', 'dnaid2017', 'dnaid2018', 'dnaid2019',\n",
    "         'dnaid2023', 'dnaid2024', 'dnaid2025', 'dnaid2026', 'dnaid2027', 'dnaid2028', 'dnaid2029' ]\n",
    "\n",
    "cnt_df = load_files(dnaids, Path(counts_dir))\n",
    "# Create unique identifier for each sample\n",
    "cnt_df['sampleID'] = cnt_df['sampleID'] + \"_\" + cnt_df['dnaid'] + \"_\" + cnt_df['experiment']\n",
    "cnt_df = cnt_df[cnt_df.sampleID.notnull()]\n",
    "cnt_df['CntrlName'] = cnt_df['phenotype'] + cnt_df['conc'].astype(str)\n",
    "cnt_df['ShortName'] = cnt_df.ShortName.fillna(cnt_df.CntrlName)\n",
    "\n",
    "# Dropping Unenriched samples\n",
    "cnt_df = cnt_df[~cnt_df.sampleID.str.contains('unenriched')]\n",
    "annotation_df = cnt_df[['barcode', 'ShortName', 'locus_tag', 'phenotype', 'conc']].drop_duplicates()\n",
    "\n",
    "libraries = [lib for lib in cnt_df.library.unique() if type(lib) == str]\n",
    "libraries.remove('library_14_1')\n",
    "print(len(libraries))\n",
    "days = ['_d1', '_d2', '_d3', '_d4']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = Path(\"/Users/ansintsova/git_repos/nguyenb_tnseq/data/08_21\")\n",
    "cnt_df.to_csv(dataDir/'old_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df.groupby('library').experiment.nunique().reset_index().sort_values('library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_per_library = cnt_df.groupby(['library', 'day']).sampleID.nunique().reset_index()\n",
    "mice_per_library\n",
    "# for library in mice_per_library.library.unique():\n",
    "#     print (mice_per_library[mice_per_library.library == library])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-boutique",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "From the above results, not enough data for library_14_1, should be dropped. At least attach warning to results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-seven",
   "metadata": {},
   "source": [
    "# Filtering the data: <a id='filtering'></a>\n",
    "\n",
    "## 1. [Checking for linearity of control dilutions](#check-linearity)\n",
    "\n",
    "## 2. [Filtering out samples with skewed WT fitness ](#check-wt-fitness)\n",
    "\n",
    "\n",
    "[Back to the start](#start)\n",
    "\n",
    "[Next to Method 1](#Method-1)\n",
    "\n",
    "[Next to Method 2](#Method-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-institute",
   "metadata": {},
   "source": [
    "# Checking for linearity of control dilutions <a id='check-linearity'></a>\n",
    "\n",
    "\n",
    "- Cutting off samples with $R^2$ < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(cnt_df, control_file, for_each='sampleID')\n",
    "print(len(good_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df.mouse.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([c.split(\"_\")[0] for c in good_samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_linearity(cnt_df, phenotype='wt', day='d0', library = 'library_10_2'):\n",
    "    query = f\"(phenotype == '{phenotype}') & (day == '{day}') & (library == '{library}')\"\n",
    "    df = cnt_df.query(query)[['barcode', 'sampleID', 'cnt', 'conc', 'library']]\n",
    "    df['lconc'] = np.log(df.conc)\n",
    "    df['lcnt'] = np.log(df.cnt +1)\n",
    "    fig = px.scatter(df.sort_values('sampleID'), \n",
    "                     x=\"lconc\", y=\"lcnt\", facet_col=\"sampleID\", facet_col_wrap=3,height=3000, width=800,\n",
    "                     trendline='ols')\n",
    "    return df, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf, fig= viz_linearity(cnt_df, day='d2', library='library_10_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-quebec",
   "metadata": {},
   "source": [
    "# Filtering out samples with skewed WT fitness <a id='check-wt-fitness'></a>\n",
    "\n",
    "- Median $log_2FC$ within -1/1 for WT barcodes\n",
    "- Filtering out technical artifacts of unknown origin\n",
    "\n",
    "### How to:\n",
    "- Only used 'good samples' identified above\n",
    "- Calculate barcode fitness for each lbirary.\n",
    "    - For each experiment in each library:\n",
    "        - Perform VST transformation\n",
    "        - Calculate fitness for each barcode $\\frac{2^{vst-barcode-counts}}{2^{vst-inoculum-counts}}$\n",
    "- Calculate WT barcode fitnesses \n",
    "- Identify samples with abs($log_2FC$) > 1\n",
    "\n",
    "[Back to the start](#start)\n",
    "\n",
    "[Next to Method 1](#Method-1)\n",
    "\n",
    "[Next to Method 2](#Method-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c00a14-ce48-489a-9075-889086c214eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_samples = []\n",
    "no_inoc_samples = []\n",
    "all_wt_fit = []\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    library_vst, library_barcode_fitness = get_barcode_fitness_by_library(cnt_df, library, good_samples, outdir, filter_below=0)\n",
    "    library_wt_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='wt')\n",
    "    all_wt_fit.append(library_wt_fitness.assign(library=library))\n",
    "    no_inoc_samples += list(library_wt_fitness.isna().all()[lambda x: x].index)\n",
    "    skewed_samples += list(get_skewed(library_wt_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38807632-79bf-4b6b-bcfa-23e62479ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_inoc_samples = ['w435_d3_dnaid1457_TV3522A',\n",
    " 'w436_d3_dnaid1457_TV3522A',\n",
    " 'w441_d4_dnaid1457_TV3522C',\n",
    " 'w443_d4_dnaid1457_TV3522C',\n",
    " 'w445_d4_dnaid1457_TV3522D',\n",
    " 'w446_d3_dnaid1457_TV3522D',\n",
    " 'w446_d4_dnaid1457_TV3522D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066ddd7-206c-47f0-88f0-d1b22e68a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(outdir)/'skewed_samples.txt', 'w') as fh:\n",
    "    for s in skewed_samples:\n",
    "        fh.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-monkey",
   "metadata": {},
   "source": [
    "# Method 1: <a id='Method-1'></a>\n",
    "\n",
    "\n",
    "- Take all the library samples, run DESeq to get fitness values\n",
    "\n",
    "\n",
    "[Back to the start](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76871aae-7692-4746-8a6d-40ce940a8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(outdir)/\"skewed_samples.txt\", 'r') as fh:\n",
    "    skewed_samples = [s.strip() for s in fh.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f278358-f050-492e-af0c-392ee848325d",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "\n",
    "- Get counts for each gene as sum of all transposons mapped to that gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75037f-69e4-4809-87ca-4059c85335f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df = cnt_df.groupby(['sampleID', 'ShortName', 'mouse', 'day', 'library', 'tissue', 'dnaid', 'experiment' ]).cnt.sum().reset_index().rename({'ShortName':'barcode'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819e18f-2759-426e-b384-bcb67a74f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "vsts = {}\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    exp_df =  gene_df[gene_df.library == library].copy()\n",
    "    library_samples = [s for s in good_samples if s in exp_df.sampleID.unique() and s not in skewed_samples  and s not in no_inoc_samples]\n",
    "    fit, res, vst = analyze_library2(exp_df, sample_id=\"sampleID\", \n",
    "                              good_samples=library_samples, \n",
    "                              dnaid=library.replace(\"_\", \"-\"), experiment='', \n",
    "                              control_file=control_file, \n",
    "                              to_filter=1000, outdir=outdir)\n",
    "    fit.columns = ['gene', 'baseMean', 'log2FC', 'lfcSE', 'stat', 'lfc_pvalue', 'lfc_padj', 'day', 'n_samples']\n",
    "    res.columns = ['gene', 'day', 'gene_FC', 'sigma', 'z-score', 'CI', 'zscore_pval', 'zscore_padj']\n",
    "    final = fit[['gene', 'log2FC', 'lfcSE', 'lfc_pvalue', 'lfc_padj', 'day', 'n_samples']].merge(res[['gene', 'day', 'z-score', 'CI', 'zscore_pval', 'zscore_padj']], how='outer', on=['gene', 'day'])\n",
    "    final = final[['gene', 'day', 'log2FC', 'lfcSE', 'lfc_pvalue', 'lfc_padj', 'z-score', 'CI', 'zscore_pval', 'zscore_padj']].assign(library=library)\n",
    "    results.append(final)\n",
    "    vsts[library] = vst\n",
    "    \n",
    "final_m1_1000 = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "a_file = open(Path(outdir)/\"27-07-vsts.pkl\", \"wb\")\n",
    "pickle.dump(vsts, a_file)\n",
    "a_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4caf7-7582-4d52-9af3-27a594160d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results = []\n",
    "# for library in libraries:\n",
    "#     print(library)\n",
    "#     exp_df =  gene_df[gene_df.library == library].copy()\n",
    "#     library_samples = [s for s in good_samples if s in exp_df.sampleID.unique() and s not in skewed_samples  and s not in no_inoc_samples]\n",
    "#     fit, res = analyze_library2(exp_df, sample_id=\"sampleID\", \n",
    "#                               good_samples=library_samples, \n",
    "#                               dnaid=library.replace(\"_\", \"-\"), experiment='', \n",
    "#                               control_file=control_file, \n",
    "# #                              to_filter=100, outdir=outdir)\n",
    "#     fit.columns = ['gene', 'baseMean', 'log2FC', 'lfcSE', 'stat', 'lfc_pvalue', 'lfc_padj', 'day', 'n_samples']\n",
    "#     res.columns = ['gene', 'day', 'gene_FC', 'sigma', 'z-score', 'CI', 'zscore_pval', 'zscore_padj']\n",
    "#     final = fit[['gene', 'log2FC', 'lfcSE', 'lfc_pvalue', 'lfc_padj', 'day', 'n_samples']].merge(res[['gene', 'day', 'z-score', 'CI', 'zscore_pval', 'zscore_padj']], how='outer', on=['gene', 'day'])\n",
    "#     final = final[['gene', 'day', 'log2FC', 'lfcSE', 'lfc_pvalue', 'lfc_padj', 'z-score', 'CI', 'zscore_pval', 'zscore_padj']].assign(library=library)\n",
    "#     results.append(final)\n",
    "# final_m1_100 = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09400905-ae67-4ec3-bcd8-dbf03e066083",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000.to_csv(Path(outdir)/'27-07-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0e59e-c285-467e-bc77-121f365e2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000[final_m1_1000.gene.str.len() < 10].gene.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266baa3d-7da9-4398-be98-65e866e14b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000[(final_m1_1000.gene.str.len() < 10) & (final_m1_1000.zscore_padj<0.05)].groupby('day').gene.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0ecbb-952c-4b20-aa3b-ec83900f9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000[(final_m1_1000.gene.str.len() < 10) & (final_m1_1000.zscore_padj<0.05)].groupby(['library','day']).gene.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9a355-9510-4acb-9fe5-43e5f9aeaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_100[final_m1_100.gene.str.len() < 10].gene.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282407c9-d517-4928-b744-d8a95615f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_100[(final_m1_100.gene.str.len() < 10) & (final_m1_100.zscore_padj<0.05)].groupby('day').gene.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20895cef-de7a-4ccc-b841-e895beae3168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff6991-b807-4818-8f0e-252cd649bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_pos = cnt_df[['ShortName','library',  'sstart', 'sseqid']].drop_duplicates().groupby(['ShortName',  'library', 'sseqid']).sstart.min().reset_index().rename({'ShortName':'gene'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_pos.to_csv(Path(outdir)/\"approx_pos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca42a85-557b-494f-8774-d3ceba210e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df[['ShortName','library',  'sstart', 'sseqid']][cnt_df.ShortName == 'siiE'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a176d30-5e01-43ba-8a20-f58c9a283a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000_pos = final_m1_1000.merge(approx_pos, on = ['gene', 'library'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9881979-e17a-4303-b240-781727145a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-manchester",
   "metadata": {},
   "source": [
    "## Remove skewed and samples with no inoculum, filter 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6d753-1cec-4bcd-99ec-2d728c0847b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_m1_1000_pos[(final_m1_1000_pos.day == 'd2')&(final_m1_1000_pos.sseqid == 'FQ312003.1')]\n",
    "test2 = test[test.zscore_padj < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a7794-b856-427d-a55f-7283d5eb471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2[(test2.sstart > 1300000) & (test2.sstart<1500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c8a34-20a1-4bae-a0cd-4311743a6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_m1_1000_pos[(final_m1_1000_pos.day == 'd1')&(final_m1_1000_pos.sseqid == 'FQ312003.1')]\n",
    "test2 = test[(test.zscore_padj < 0.05) & (abs(np.log2(test.CI)) > 1)]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (40, 10))\n",
    "plt.scatter(test.sstart, test.CI, color='grey', alpha=0.2)\n",
    "plt.scatter(test2.sstart, test2.CI, color='red', alpha=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5caca-e519-43dd-8b07-13a5d6590660",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_m1_1000_pos[(final_m1_1000_pos.day == 'd2')&(final_m1_1000_pos.sseqid == 'FQ312003.1')]\n",
    "test2 = test[(test.zscore_padj < 0.05) & (abs(np.log2(test.CI)) > 1)]\n",
    "\n",
    "plt.figure(figsize = (40, 10))\n",
    "plt.scatter(test.sstart, test.CI, color='grey', alpha=0.2)\n",
    "plt.scatter(test2.sstart, test2.CI, color='red', alpha=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf24b03-620d-4831-bead-43cd5ffba390",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_m1_1000_pos.sseqid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d8dfb-34cd-456d-bab6-ae37e600b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a5c76-c6b5-45d0-b32a-0b8fbb36aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "test = final_m1_1000_pos[(final_m1_1000_pos.sseqid == 'FQ312003.1')]\n",
    "test2 = test[(test.zscore_padj < 0.05) & (abs(np.log2(test.CI)) > 1)].sort_values('day')\n",
    "plt.figure(figsize = (40, 10))\n",
    "sns.stripplot(x = test2.sstart, y=test2.day)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed477f74-2703-4bdd-b758-77828d6449ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2 = test[['CI', 'day', 'gene', 'library']].pivot(index=['gene', 'library'], columns='day', values='CI').reset_index().set_index('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2eb2bc-ac57-4113-8d77-71018e4f1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fe2be-2b33-4d61-b220-461a56bd1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_m1_1000_pos[(final_m1_1000_pos.day == 'd3')&(final_m1_1000_pos.sseqid == 'FQ312003.1')]\n",
    "test2 = test[(test.zscore_padj < 0.05) & (abs(np.log2(test.CI)) > 1)]\n",
    "\n",
    "plt.figure(figsize = (40, 10))\n",
    "plt.scatter(test.sstart, test.CI, color='grey',alpha=0.2)\n",
    "plt.scatter(test2.sstart, test2.CI, color='red', alpha=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b02ab3-5d7a-4cdd-8878-031c85046118",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = final_m1_1000_pos[(final_m1_1000_pos.day == 'd4')&(final_m1_1000_pos.sseqid == 'FQ312003.1')]\n",
    "test2 = test[(test.zscore_padj < 0.05) & (abs(np.log2(test.CI)) > 1)]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (40, 10))\n",
    "plt.scatter(test.sstart, test.CI, color='grey', alpha=0.2)\n",
    "plt.scatter(test2.sstart, test2.CI, color='red', alpha=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7ac53-ae75-4785-998e-8df493dce78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for library in ['library_10_2']:\n",
    "    print(library)\n",
    "    lib_df = cnt_df[cnt_df.library == library].copy()\n",
    "    #Removing some noise\n",
    "    lib_df = lib_df[~((lib_df.libcnt.isna()) & (lib_df.phenotype.isna()))]\n",
    "    library_samples = [s for s in good_samples if s in lib_df.sampleID.unique() and s not in skewed_samples \n",
    "                      and s not in no_inoc_samples]\n",
    "    fit, res = analyze_library(lib_df, sample_id=\"sampleID\", \n",
    "                          good_samples=library_samples, \n",
    "                          dnaid=library.replace(\"_\", \"-\"), experiment='', \n",
    "                          control_file=control_file, \n",
    "                          to_filter=100, outdir=outdir)\n",
    "    results.append(res)\n",
    "    \n",
    "method1_skewed_removed = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e905a-2d12-459c-8e63-f123be0b84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_comp = method1_skewed_removed.merge(m1_b_res, on=['gene', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4ab10-ab7d-4141-9aa3-5c3eac8b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981eacd2-18fb-4aca-9eea-6ba946b01e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(m1_comp.ci_x, m1_comp.ci_y)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-deputy",
   "metadata": {},
   "source": [
    "## Remove skewed and samples with no inoculum, filter 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    lib_df = cnt_df[cnt_df.library == library].copy()\n",
    "    #Removing some noise\n",
    "    lib_df = lib_df[~((lib_df.libcnt.isna()) & (lib_df.phenotype.isna()))]\n",
    "    library_samples = [s for s in good_samples if s in lib_df.sampleID.unique() and s not in skewed_samples \n",
    "                      and s not in no_inoc_samples]\n",
    "    fit, res = analyze_library(lib_df, sample_id=\"sampleID\", \n",
    "                          good_samples=library_samples, \n",
    "                          dnaid=library.replace(\"_\", \"-\"), experiment='', \n",
    "                          control_file=control_file, \n",
    "                          to_filter=100, outdir=outdir)\n",
    "    results.append(res)\n",
    "    \n",
    "method1_skewed_removed_100 = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95aad5-e698-48ee-a999-a5385da3c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    lib_df = cnt_df[cnt_df.library == library].copy()\n",
    "    #Removing some noise\n",
    "    lib_df = lib_df[~((lib_df.libcnt.isna()) & (lib_df.phenotype.isna()))]\n",
    "    library_samples = [s for s in good_samples if s in lib_df.sampleID.unique() if s not in no_inoc_samples]\n",
    "    fit, res = analyze_library(lib_df, sample_id=\"sampleID\", \n",
    "                          good_samples=library_samples, \n",
    "                          dnaid=library.replace(\"_\", \"-\"), experiment='', \n",
    "                          control_file=control_file, \n",
    "                          to_filter=1000, outdir=outdir)\n",
    "    results.append(res)\n",
    "    \n",
    "method1_with_skewed = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "method1_skewed_removed_100.to_csv(Path(outdir)/\"21-07-method1_skewed_removed_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e28dd-f5d8-4be3-93b5-a6c8a04f0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "method1_skewed_removed.to_csv(Path(outdir)/\"21-07-method1_skewed_removed.csv\")\n",
    "method1_with_skewed.to_csv(Path(outdir)/\"21-07-method1_with_skewed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-gibson",
   "metadata": {},
   "source": [
    "# Method 2: <a id='Method-2'></a>\n",
    "\n",
    "[Back to the start](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples_noskew = [s for s in good_samples if s not in skewed_samples and s not in no_inoc_samples]\n",
    "vsts = {}\n",
    "fits = []\n",
    "cis = []\n",
    "wt_fits = []\n",
    "ssa_ci = []\n",
    "resultsFitList = []\n",
    "resultsCIList=[]\n",
    "# Fitness Results\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    library_vst, library_barcode_fitness = get_barcode_fitness_by_library(cnt_df, library, good_samples_noskew, outdir, filter_below=1000)\n",
    "    library_gene_fitness = get_gene_fitness_by_library(library_barcode_fitness, annotation_df)\n",
    "    library_wt_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='wt')\n",
    "    library_ssa_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='ssaV_invG')\n",
    "    library_gene_ci = library_gene_fitness.set_index('ShortName').apply(lambda x: x / library_wt_fitness.median()[x.name]).reset_index()\n",
    "    library_ssa_ci = library_ssa_fitness.median()/library_wt_fitness.median()\n",
    "    meltGeneFit = melt_sampleID(library_gene_fitness, idVar=['ShortName'], value_name='fitness')\n",
    "    meltWtFit = melt_sampleID(library_wt_fitness, idVar=['barcode', 'phenotype', 'conc'], value_name='fitness')\n",
    "    meltGeneCI = melt_sampleID(library_gene_ci, idVar=['ShortName'], value_name='ci')\n",
    "    resultsFit = get_library_results(meltGeneFit, meltWtFit, library)\n",
    "    resultsCI = get_library_results_ci(meltGeneCI, library_ssa_ci, library)\n",
    "    \n",
    "    fits.append(meltGeneFit.assign(library=library))\n",
    "    cis.append(meltGeneCI.assign(library=library))\n",
    "    wt_fits.append(meltWtFit.assign(library=library))\n",
    "    resultsFitList.append(resultsFit)\n",
    "    resultsCIList.append(resultsCI)\n",
    "    ssa_ci.append(pd.DataFrame(library_ssa_ci, columns=['ssa_ci']).assign(library=library))\n",
    "    vsts[library]= library_vst\n",
    "      \n",
    "m2_fits_no_skew = pd.concat(fits)\n",
    "m2_ci_no_skew = pd.concat(cis)\n",
    "m2_wt_fits_no_skew = pd.concat(wt_fits)\n",
    "m2_results_fit_no_skew = pd.concat(resultsFitList)\n",
    "m2_results_ci_no_skew = pd.concat(resultsCIList)\n",
    "m2_ssa_ci_no_skew = pd.concat(ssa_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = {s:['median'] for s in library_vst}\n",
    "sample_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-shield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = {s:['median'] for s in vsts['library_14_2']}\n",
    "test_gene = (vsts['library_14_2'].reset_index()\n",
    " .merge(annotation_df, on='barcode').drop(['locus_tag', 'phenotype', 'conc'], axis=1)\n",
    " .set_index('barcode')\n",
    " .groupby('ShortName').agg(sample_map))\n",
    "test_gene.columns = [c[0] for c in test_gene.columns]\n",
    "genes = test_gene.var(axis=1).sort_values(ascending=False).head(50).index\n",
    "test_gene = test_gene.loc[genes]\n",
    "df, pc1, pc2 = get_pca_df(test_gene)\n",
    "plotPCA(df, pc1,pc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_pca_df(library_vst, num_genes=500):\n",
    "    var_bcs = library_vst.var(axis=1).sort_values(ascending=False).head(num_genes).index\n",
    "    df = library_vst.loc[var_bcs]\n",
    "    meta = library_vst.T.reset_index().rename({'index':'sampleID'}, axis=1)\n",
    "    new = meta.sampleID.str.split(\"_\", expand=True)\n",
    "    new.columns = ['mouse', 'day', 'dnaid', 'experiment']\n",
    "    meta = pd.concat([meta[['sampleID']], new], axis=1).set_index('sampleID')\n",
    "    pDf, pc1_var, pc2_var = find_pc1_pc2(df, meta)\n",
    "    return pDf, pc1_var, pc2_var\n",
    "\n",
    "\n",
    "def plotPCA(pDf, pc1, pc2, title=\"\"):\n",
    "    fig = px.scatter(pDf.sort_values('day'), x='PC1', y='PC2', color='day', symbol='experiment', hover_data=['mouse'],\n",
    "              template='simple_white', title=title,\n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "                labels ={'PC1': f'PC1, {pc1}%',\n",
    "                        'PC2': f'PC2, {pc2}%',\n",
    "                        'day': 'Day',\n",
    "                        'experiment': 'Experiment'})\n",
    "\n",
    "\n",
    "    fig.update_traces(marker=dict(size=12,\n",
    "                                  line=dict(width=2,\n",
    "                                            color='DarkSlateGrey')),\n",
    "                      selector=dict(mode='markers'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        font_family=\"Arial\",\n",
    "        font_size=14,\n",
    "        title_font_size=24,\n",
    "        title_x=0.5\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pDf, pc1, pc2 = get_pca_df(vsts['library_10_2'], 50)\n",
    "plotPCA(pDf, pc1, pc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "\n",
    "for library in libraries:\n",
    "    pDf, pc1, pc2 = get_pca_df(vsts[library])\n",
    "    figs.append(plotPCA(pDf, pc1, pc2, library))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(outdir)/'PCA_barcode_abundance.html', 'a') as f:\n",
    "    for fig in figs:\n",
    "        f.write(fig.to_html())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gene.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = sns.clustermap(\n",
    "    test_gene, \n",
    "    cmap=sns.diverging_palette(10, 220, n=256),\n",
    "    \n",
    "    figsize=(20,20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-boxing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pc1_pc2(df, meta):\n",
    "    df = df.T\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(df)\n",
    "    pDf = (pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n",
    "           .set_index(df.index))\n",
    "\n",
    "    pc1_var = round(pca.explained_variance_ratio_[0] * 100, 2)\n",
    "    pc2_var = round(pca.explained_variance_ratio_[1] * 100, 2)\n",
    "    pDf2 = pDf.merge(meta, left_index=True, right_index=True)\n",
    "    return pDf2, pc1_var, pc2_var\n",
    "\n",
    "\n",
    "def plotPCA(pDf, pc1_var, pc2_var, colorby, col, nameby=\"\", el=False):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"notebook\", font_scale=2.2)\n",
    "    group = pDf[colorby].unique()\n",
    "    assert len(group) <= len(col)\n",
    "    fig = plt.figure(figsize=(25, 15))\n",
    "    for g, c in zip(group, col):\n",
    "        df = pDf[pDf[colorby] == g]\n",
    "        x, y = df[[\"PC1\"]].values, df[[\"PC2\"]].values\n",
    "        ax = plt.scatter(x, y, c=c, s=150, label=g)\n",
    "        if el:\n",
    "            pts = np.asarray([[float(a), float(b)] for a, b in zip(x, y)])\n",
    "            plot_point_cov(pts, nstd=2, alpha=0.1, color=c)\n",
    "        if nameby:\n",
    "            labels = df[nameby]\n",
    "            for label, pc1, pc2 in zip(labels, x, y):\n",
    "                plt.annotate(label, xy=(pc1, pc2), xytext=(-5, 7), textcoords=\"offset points\",fontsize=14)\n",
    "        plt.xlabel('Principal Component 1, {} %'.format(pc1_var), )\n",
    "        plt.ylabel('Principal Component 2, {} %'.format(pc2_var), )\n",
    "        #plt.xticks(fontsize=16)\n",
    "        #plt.yticks(fontsize=16)\n",
    "        plt.legend(frameon=True)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = [c[1] for c in test_df.columns]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-wells",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "new = vsts[0].sampleID.str.split(\"_\", expand=True)\n",
    "new.columns = ['mouse', 'day', 'dnaid', 'experiment']\n",
    "meta = pd.concat([vsts[0][['library', 'sampleID']], new], axis=1).set_index('sampleID')\n",
    "\n",
    "pDf, pc1_var, pc2_var = find_pc1_pc2(test_df, meta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta.day == 'd0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(20,30))\n",
    "ax = sns.clustermap(\n",
    "    library_gene_fitness[[c for c in library_gene_fitness.columns if 'd0' not in c]].corr(), \n",
    "    \n",
    "    cmap=sns.diverging_palette(10, 220, n=256),\n",
    "    square=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_gene_fitness.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aab864-7f2c-4795-9935-621588880d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples_noskew = [s for s in good_samples if s not in skewed_samples and s not in no_inoc_samples]\n",
    "fits = []\n",
    "cis = []\n",
    "wt_fits = []\n",
    "ssa_ci = []\n",
    "resultsFitList = []\n",
    "resultsCIList=[]\n",
    "# Fitness Results\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    library_vst, library_barcode_fitness = get_barcode_fitness_by_library(cnt_df, library, good_samples_noskew, outdir, filter_below=1000)\n",
    "    library_gene_fitness = get_gene_fitness_by_library(library_barcode_fitness, annotation_df)\n",
    "    library_wt_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='wt')\n",
    "    library_ssa_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='ssaV_invG')\n",
    "    library_gene_ci = library_gene_fitness.set_index('ShortName').apply(lambda x: x / library_wt_fitness.median()[x.name]).reset_index()\n",
    "    library_ssa_ci = library_ssa_fitness.median()/library_wt_fitness.median()\n",
    "    meltGeneFit = melt_sampleID(library_gene_fitness, idVar=['ShortName'], value_name='fitness')\n",
    "    meltWtFit = melt_sampleID(library_wt_fitness, idVar=['barcode', 'phenotype', 'conc'], value_name='fitness')\n",
    "    meltGeneCI = melt_sampleID(library_gene_ci, idVar=['ShortName'], value_name='ci')\n",
    "    resultsFit = get_library_results(meltGeneFit, meltWtFit, library)\n",
    "    resultsCI = get_library_results_ci(meltGeneCI, library_ssa_ci, library)\n",
    "    \n",
    "    fits.append(meltGeneFit.assign(library=library))\n",
    "    cis.append(meltGeneCI.assign(library=library))\n",
    "    wt_fits.append(meltWtFit.assign(library=library))\n",
    "    resultsFitList.append(resultsFit)\n",
    "    resultsCIList.append(resultsCI)\n",
    "    ssa_ci.append(pd.DataFrame(library_ssa_ci, columns=['ssa_ci']).assign(library=library))\n",
    "    \n",
    "m2_fits_no_skew = pd.concat(fits)\n",
    "m2_ci_no_skew = pd.concat(cis)\n",
    "m2_wt_fits_no_skew = pd.concat(wt_fits)\n",
    "m2_results_fit_no_skew = pd.concat(resultsFitList)\n",
    "m2_results_ci_no_skew = pd.concat(resultsCIList)\n",
    "m2_ssa_ci_no_skew = pd.concat(ssa_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a839f-8f8d-4d6c-b420-c65f6fadfcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fits = []\n",
    "cis = []\n",
    "wt_fits = []\n",
    "ssa_ci = []\n",
    "resultsFitList = []\n",
    "resultsCIList=[]\n",
    "# Fitness Results\n",
    "for library in libraries:\n",
    "    print(library)\n",
    "    library_vst, library_barcode_fitness = get_barcode_fitness_by_library(cnt_df, library, good_samples, outdir, filter_below=1000)\n",
    "    library_gene_fitness = get_gene_fitness_by_library(library_barcode_fitness, annotation_df)\n",
    "    library_wt_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='wt')\n",
    "    library_ssa_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='ssaV_invG')\n",
    "    library_gene_ci = library_gene_fitness.set_index('ShortName').apply(lambda x: x / library_wt_fitness.median()[x.name]).reset_index()\n",
    "    library_ssa_ci = library_ssa_fitness.median()/library_wt_fitness.median()\n",
    "    meltGeneFit = melt_sampleID(library_gene_fitness, idVar=['ShortName'], value_name='fitness')\n",
    "    meltWtFit = melt_sampleID(library_wt_fitness, idVar=['barcode', 'phenotype', 'conc'], value_name='fitness')\n",
    "    meltGeneCI = melt_sampleID(library_gene_ci, idVar=['ShortName'], value_name='ci')\n",
    "    resultsFit = get_library_results(meltGeneFit, meltWtFit, library)\n",
    "    resultsCI = get_library_results_ci(meltGeneCI, library_ssa_ci, library)\n",
    "    \n",
    "    fits.append(meltGeneFit.assign(library=library))\n",
    "    cis.append(meltGeneCI.assign(library=library))\n",
    "    wt_fits.append(meltWtFit.assign(library=library))\n",
    "    resultsFitList.append(resultsFit)\n",
    "    resultsCIList.append(resultsCI)\n",
    "    ssa_ci.append(pd.DataFrame(library_ssa_ci, columns=['ssa_ci']).assign(library=library))\n",
    "    \n",
    "m2_fits_skew = pd.concat(fits)\n",
    "m2_ci_skew = pd.concat(cis)\n",
    "m2_wt_fits_skew = pd.concat(wt_fits)\n",
    "m2_results_fit_skew = pd.concat(resultsFitList)\n",
    "m2_results_ci_skew = pd.concat(resultsCIList)\n",
    "m2_ssa_ci_skew = pd.concat(ssa_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f07287-8a48-48b2-88ff-b89e7cd6af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_fits_no_skew.to_csv(Path(outdir)/\"21-07-m2_fits_no_skew\")\n",
    "m2_ci_no_skew.to_csv(Path(outdir)/\"21-07-m2_ci_no_skew\")\n",
    "m2_wt_fits_no_skew.to_csv(Path(outdir)/\"21-07-m2_wt_fits_no_skew\")\n",
    "m2_results_fit_no_skew.to_csv(Path(outdir)/\"21-07-m2_results_fit_no_skew\")\n",
    "m2_results_ci_no_skew.to_csv(Path(outdir)/\"21-07-m2_results_ci_no_skew\")\n",
    "m2_ssa_ci_no_skew.to_csv(Path(outdir)/\"21-07-m2_ssa_ci_no_skew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c838f47-9c93-4d9d-bdb5-a8ebea97fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_fits_skew.to_csv(Path(outdir)/\"21-07-m2_fits_skew\")\n",
    "m2_ci_skew.to_csv(Path(outdir)/\"21-07-m2_ci_skew\")\n",
    "m2_wt_fits_skew.to_csv(Path(outdir)/\"21-07-m2_wt_fits_skew\")\n",
    "m2_results_fit_skew.to_csv(Path(outdir)/\"21-07-m2_results_fit_skew\")\n",
    "m2_results_ci_skew.to_csv(Path(outdir)/\"21-07-m2_results_ci_skew\")\n",
    "m2_ssa_ci_skew.to_csv(Path(outdir)/\"21-07-m2_ssa_ci_skew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b587d9f-a70b-4407-a2d7-d1c69f837d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_results_fit_no_skew.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8aac5-7c43-4959-8f6b-7d7da420764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI Results: \n",
    "library_ssa_fitness = get_wt_fitness_by_library(library_barcode_fitness, annotation_df, phenotype='ssaV_invG')\n",
    "\n",
    "meltSsaFit = melt_sampleID(library_ssa_fitness, idVar=['barcode', 'phenotype', 'conc'], value_name='fitness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4988757-614f-4bc3-8e70-cfd2e68c3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_gene_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8019036-15d8-4d07-b458-adf1363a1074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a58dc-900d-455c-93c9-19f70edb10c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8858f16-8109-4f19-8e75-82a85186ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_gene_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6febd-00fb-4b52-abaa-c3b6329b1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "meltGeneFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3f7ad-d888-486b-9111-fb53a9641585",
   "metadata": {},
   "outputs": [],
   "source": [
    "meltSsaFit[['sampleID', 'fitness']].set_index('sampleID')/meltWtFit[['sampleID', 'fitness']].set_index('sampleID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ed947-afd9-46aa-9d91-e52e10b8d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "meltSsaFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed809ff9-d6de-4c7c-ae31-61e0739881b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_ssa_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ac0d6-5a83-4d61-accf-2e07a35c6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = meltGeneFit[['ShortName', 'day']].drop_duplicates()\n",
    "y[y.day !='d0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc05f68-b8d3-493d-8e08-cd52831ebc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results.merge(meltGeneFit[['ShortName', 'day']].drop_duplicates(), on=['ShortName', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf466b3-aed8-44c9-85ec-e13a5cab8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dfs = []\n",
    "gene_fit_dfs = []\n",
    "ci_dfs = []\n",
    "res_dfs = []\n",
    "wt_fit_dfs = []\n",
    "ssa_ci_dfs = []\n",
    "\n",
    "for library in ['library_10_2']:\n",
    "    print(library)\n",
    "    lib_df = cnt_df[cnt_df.library == library].copy()\n",
    "    #Removing some noise\n",
    "    lib_df = lib_df[~((lib_df.libcnt.isna()) & (lib_df.phenotype.isna()))]\n",
    "    library_samples = [s for s in good_samples if s in lib_df.sampleID.unique() and s not in skewed_samples]\n",
    "    sdf, edf, design = generate_DE_dataset(lib_df, library_samples, sample_id='sampleID', filter_below=1000)\n",
    "    _, vst_df = get_fitness_results(outdir, library.replace(\"_\", \"-\"), '', sdf, edf, design)\n",
    "    method2_results = method2_analysis2(vst_df, annotation_df, library_samples, sample_id='sampleID', hits=0.05)\n",
    "    \n",
    "    for df in method2_results:\n",
    "        if not df.empty:\n",
    "            df['library'] = library\n",
    "    all_fitness_df, gene_fitness_df, ci_df, results_df, wt_fitness_df, ssa_ci_df = method2_results    \n",
    "    fit_dfs.append(all_fitness_df)\n",
    "    gene_fit_dfs.append(gene_fitness_df)\n",
    "    ci_dfs.append(ci_df)\n",
    "    res_dfs.append(results_df)\n",
    "    wt_fit_dfs.append(wt_fitness_df)\n",
    "    ssa_ci_dfs.append(ssa_ci_df)\n",
    "    \n",
    "fit2 = pd.concat(fit_dfs)\n",
    "fit2_gene = pd.concat(gene_fit_dfs)\n",
    "wt_fit2 = pd.concat(wt_fit_dfs)\n",
    "ssa_ci2 = pd.concat(ssa_ci_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pd.concat(res_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.sample(5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby('day').padj.count()\n",
    "#print('Tested 1888 genes/barcodes')\n",
    "for day in ['d1', 'd2', 'd3', 'd4']:\n",
    "    print(f'Number of significant hits on {day}: {res2[(res2.day == day)&(res2.ci_padj < 0.05)].shape[0]}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_control_df(fitness, phenotype='wt'):\n",
    "    fitness.columns = [c.replace(\"unenriched_\", \"unenriched-\") for c in fitness.columns]\n",
    "    fitness = fitness.drop(['day'], axis=1)\n",
    "\n",
    "    wt = fitness[fitness.phenotype == phenotype].dropna(axis=1).drop(['inoculum'], axis=1)\n",
    "    wt = wt.melt(id_vars=['barcode', 'phenotype', 'conc', 'library'], var_name='sampleID', value_name='fitness')\n",
    "    new = wt.sampleID.str.split(\"_\", expand=True)\n",
    "    new.columns = ['mouse', 'day', 'dnaid', 'experiment']\n",
    "    wt = wt.merge(new, left_index=True, right_index=True)\n",
    "    return wt\n",
    "\n",
    "wt = get_control_df(all_fitness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 'd3'\n",
    "wt_d1 = wt[wt.day == day]\n",
    "fig = px.box(wt_d1, x='mouse', y=np.log2(wt_d1['fitness']), color='mouse',  hover_data=['conc', 'fitness'],\n",
    "        template='simple_white', title = f'WT-{day}',\n",
    "              labels={\"y\": \"log2(Fitness)\",\n",
    "                     \"conc\": \"Dilution\", \"fitness\": \"Fitness\"})\n",
    "fig.add_hline(y=0, line_width=3, line_dash=\"dash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_skewed = wt.groupby('sampleID').agg({'fitness': [lambda x: x.quantile(0.25),  lambda x: x.quantile(0.75)]}).reset_index()\n",
    "filter_skewed.columns = ['sampleID', 'lowQ', 'highQ']\n",
    "filter_skewed = filter_skewed[~(filter_skewed.lowQ<1.1)&(filter_skewed.highQ>0.9)]\n",
    "to_drop = filter_skewed.sampleID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-salon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.loc['rfaI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_fit2.groupby('day').wt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_ranksums(gene_values, wt_values):\n",
    "    return ranksums(gene_values, wt_values)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv = ci2[(ci2.ShortName == 'rfaI') & (ci2.day == 'd4')].CI.values\n",
    "wv = ssa_ci2.loc[ssa_ci2.day == 'd4'].CI.values\n",
    "gene_ranksums(gv, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.loc['rfaI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.day.str.split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivars = ['gene', 'locus', 'num_barcodes', 'library', 'barcode', 'sstart', 'sseqid']\n",
    "vvars = ['num_samples', 'fitness_mean', 'fitness_std', 'ci', 'zscore', 'pval', 'padj']\n",
    "df_list = []\n",
    "for v in vvars:\n",
    "    t = res1.reset_index().melt(id_vars = ivars, value_vars=[c for c in res1.columns if v in c], value_name=v, var_name='day')\n",
    "    t['day'] = t.day.str.split(\"_\", expand=True)[0]\n",
    "    df_list.append(t)\n",
    "res1m = pd.concat(df_list, axis=1)\n",
    "res1m = res1m.loc[:, ~res1m.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-japan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1m.groupby(['library', 'day']).agg({'padj': [significant]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.groupby(['library', 'day']).agg({'ci_padj': [significant]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1m[(res1m.library == 'library_10_2') & (res1m.day=='d1')].sort_values('padj').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_fit2[wt_fit2.library == 'library_11_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in ['library_10_2']:\n",
    "    print(library)\n",
    "    lib_df = cnt_df[cnt_df.library == library].copy()\n",
    "    library_samples = [s for s in good_samples if s in lib_df.sampleID.unique()]\n",
    "    vst_df = run_VST_transformation(lib_df, library.replace(\"_\", '-'), good_samples, \n",
    "                                    outdir, sample_id='sampleID').set_index('barcode')\n",
    "    method2_results = method2_analysis(vst_df, annotation_df, library_samples, sample_id='sampleID', hits=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vst_df.sample(5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fitness_df, gene_fitness_df, ci_df, results_df, wt_fitness_df, ssa_ci_df = method2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.ci_hits.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vst_test = cnt_df[(cnt_df.library=='library_10_2') & (cnt_df.day == 'd1')][['barcode', 'cnt', 'sampleID']].drop_duplicates()\n",
    "\n",
    "vst_test = vst_test.set_index('barcode').pivot(columns='sampleID').fillna(0)\n",
    "vst_test.columns = [c[1] for c in vst_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vst_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=vst_test.mean(axis=1), y=vst_test.var(axis=1)/vst_test.mean(axis=1), log_x=True, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = np.log(vst_test)\n",
    "step2 = step1.mean(axis=1)\n",
    "step3 = step2.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "step4 = step1.T.apply(lambda x: x - x.mean()).T.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "step5 = step4.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors = step5.apply(math.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors['ad926_d1_dnaid2017_TV4592A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vst = vst_test.apply(lambda x: x/scaling_factors[x.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.exp(7.69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=norm_vst.mean(axis=1), y=norm_vst.var(axis=1)/vst_test.mean(axis=1), log_x=True, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-composition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
