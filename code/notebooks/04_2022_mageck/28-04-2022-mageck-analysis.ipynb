{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.437574Z",
     "start_time": "2022-05-02T13:04:51.171305Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../snippets/basic_settings.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import yaml\n",
    "\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 12)\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['text.usetex'] = False  # True activates latex output in fonts!\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.serif'] = \"cm\"\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.446554Z",
     "start_time": "2022-05-02T13:04:54.441785Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.557432Z",
     "start_time": "2022-05-02T13:04:54.449018Z"
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"../nguyenb_config.yaml\"\n",
    "with open(config_file) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    configs = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.653484Z",
     "start_time": "2022-05-02T13:04:54.561629Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run on server:\n",
    "root = Path(configs['root']['server'])\n",
    "scratchDir = Path(configs['scratchDir']['server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.763600Z",
     "start_time": "2022-05-02T13:04:54.656905Z"
    }
   },
   "outputs": [],
   "source": [
    "mapDir = root/configs['mapDir']\n",
    "countDir = root/configs['libraryCountsDir']\n",
    "resultDir = root/configs['resultDir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.869738Z",
     "start_time": "2022-05-02T13:04:54.767012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def run_command(args):\n",
    "    \"\"\"Run command, transfer stdout/stderr\"\"\"\n",
    "    result = subprocess.run(args)\n",
    "    try:\n",
    "        result.check_returncode()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data \n",
    "- Using data from library_11_1 as a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:54.982302Z",
     "start_time": "2022-05-02T13:04:54.873190Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_merged_count_file(merged_count_file):\n",
    "    counts = pd.read_csv(merged_count_file)\n",
    "    annotation_cols = list(counts.columns[0:2])\n",
    "    sampleIDs = list(counts.columns[2:])\n",
    "    return counts, annotation_cols, sampleIDs\n",
    "\n",
    "\n",
    "def calculate_cpms(merged_df, annotation_cols, sampleIDs):\n",
    "    merged_df = merged_df[merged_df.sum(axis=1, numeric_only=True) > 10]\n",
    "    # Normalized for library depth and log transform\n",
    "    cpms = merged_df.copy().set_index(list(annotation_cols))\n",
    "    cpms = np.log2(cpms/cpms.sum()*1000000 +0.5).reset_index()\n",
    "    return cpms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:04:17.133018Z",
     "start_time": "2022-04-28T15:04:17.118967Z"
    }
   },
   "source": [
    "## Extract counts for control barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:55.094007Z",
     "start_time": "2022-05-02T13:04:54.986784Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_in_control_file(control_file: Union[str, Path]):\n",
    "    \"\"\"\n",
    "    Control file: No header\n",
    "    \n",
    "    [barcode],[conc],[phenotype]\n",
    "    \n",
    "    1. Check that the first column contains barcodes\n",
    "    2. Check that second column is numeric -> should contain concentrations\n",
    "    3. If there is a thrid column it should be string, and at least one should be ['wt', 'WT', 'wildtype']\n",
    "    \n",
    "    \"\"\"\n",
    "    cntrl_df = pd.read_csv(control_file, header=None)\n",
    "    num_cols = cntrl_df.shape[1]\n",
    "    \n",
    "    # Add column validation code here\n",
    "    \n",
    "    col_names = ['barcode', 'concentration', 'genotype']\n",
    "    cntrl_df.columns = col_names[0:num_cols]\n",
    "    \n",
    "    if num_cols == 3:\n",
    "        if any(cntrl_df.genotype.isin(['wt', 'WT', 'wildtype'])):\n",
    "            wt_barcodes = cntrl_df[cntrl_df.genotype.isin(['wt', 'WT', 'wildtype'])].barcode.values\n",
    "        else:\n",
    "            wt_barcodes = []\n",
    "    else:\n",
    "        wt_barcodes = cntrl_df.barcode.values\n",
    "    return cntrl_df, wt_barcodes\n",
    "\n",
    "\n",
    "def get_control_counts(cntrl_df: pd.DataFrame, wt_barcodes: List, counts_df: pd.DataFrame, \n",
    "                      annotations_col: List) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    counts_df: \n",
    "    barcode,geneName,sample1,sample2\n",
    "    \n",
    "    Merge left, convert NA to 0 \n",
    "    return merged data frame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_cols = cntrl_df.shape[1]\n",
    "    if annotations_col[0] != 'barcode':\n",
    "        counts_df = counts_df.rename({annotations_col[0]: 'barcode'}, axis=1)\n",
    "    # Add column validation for counts_df\n",
    "    fdf = cntrl_df.merge(counts_df, how='left', on='barcode').fillna(0)\n",
    "    if len(wt_barcodes) > 0:\n",
    "        wt_df = fdf[fdf.barcode.isin(wt_barcodes)]\n",
    "    else:\n",
    "        wt_df = pd.DataFrame()\n",
    "    return wt_df, fdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:55.375289Z",
     "start_time": "2022-05-02T13:04:55.366870Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_correlation(control_df: pd.DataFrame, sampleIDs: List, cutoff: float=0.8):\n",
    "    \"\"\"\n",
    "    Given a data frame with a 'concentration' column and sampleID (normalised) counts + list of sampleIDs, \n",
    "    calculate correlation between concentration \n",
    "    return a list of 'good samples', i.e. passing the cutoff\n",
    "    \n",
    "    Assert concentration column is present\n",
    "    Assert sampleIDs are in control_df columns\n",
    "    \"\"\"\n",
    "    concentrations = np.log2(control_df.concentration)\n",
    "    samples = control_df[sampleIDs]\n",
    "    corr_df = pd.DataFrame(samples.corrwith(concentrations), columns=['R'])\n",
    "    corr_df[\"R2\"] = corr_df.R**2\n",
    "    good_samples = list(corr_df[corr_df.R2 > cutoff].index)\n",
    "    return corr_df, good_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:55.997300Z",
     "start_time": "2022-05-02T13:04:55.992358Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_correlation_plots(control_df, sampleIDs):\n",
    "    \"\"\"\n",
    "    given a complete control_df, draw correlation plot for each sampleID for each genotype\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:56.259793Z",
     "start_time": "2022-05-02T13:04:56.254194Z"
    }
   },
   "outputs": [],
   "source": [
    "not_found_in_dnaid1315 = ['AACAACACGGTAAGCAA', 'AGAATGACCCGGAGGCT', 'AGTCATCGATGCTATAT', 'CCGACGACTGATTGTCC',\n",
    "           'CTACGACAGGGACTTAA', 'GTGTATAGCAGGAACCC', 'GTGTATAGCAGGAACCC', 'TAAGTCCGGGCTAAGTC',\n",
    "           'TATAACACCCCCGATTC', 'TCTCACGCAGCGTTTCG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:56.586464Z",
     "start_time": "2022-05-02T13:04:56.581923Z"
    }
   },
   "outputs": [],
   "source": [
    "# cdf1 = cdf[[1]]\n",
    "# cdf1.to_csv(root/\"controls_1col.csv\", index=False, header=None)\n",
    "# cdf2 = cdf[[1,3]]\n",
    "# cdf2.to_csv(root/\"controls_2col.csv\", index=False,header=None)\n",
    "# cdf3 = cdf[[1,3,2]]\n",
    "# cdf3.to_csv(root/\"controls_3col.csv\", index=False,header=None)\n",
    "#wt_df[['barcode', 'concentration']].to_csv(root/\"controls_6barcodes.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAGeCK Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare MAGeCK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:58.222808Z",
     "start_time": "2022-05-02T13:04:58.211465Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_mageck_dataset(counts_df, sampleData, control_barcodes, annotation_cols, good_samples, name, \n",
    "                           batch_col, treatment_col, outDir):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Assume the first column of sampleData contains sampleIDs.\n",
    "    Assume second has geneName\n",
    "    The rest are raw counts for samples in sampleIDs.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    batch_file = outDir/f\"{name}_batch.txt\"\n",
    "    count_file = outDir/f\"{name}_count.txt\"\n",
    "    sampleID_col = sampleData.columns[0]\n",
    "\n",
    "    batch_df = (sampleData[sampleData[sampleID_col].isin(good_samples)]\n",
    "                [[sampleID_col, batch_col, treatment_col]]\n",
    "                .sort_values([treatment_col, batch_col]))\n",
    "\n",
    "    batch_df.to_csv(batch_file, index=False, sep='\\t')\n",
    "    magDf = counts_df[annotation_cols + good_samples].copy()\n",
    "    magDf.loc[magDf[annotation_cols[0]].isin(control_barcodes), annotation_cols[1]] = 'control'\n",
    "    magDf = magDf.dropna(subset=annotation_cols).fillna(0)\n",
    "    magDf.to_csv(count_file, index=False, sep='\\t')\n",
    "    return batch_file, count_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MAGeCK batch correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:59.366918Z",
     "start_time": "2022-05-02T13:04:59.361102Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_in_sample_data(sample_data_file, sampleIDs, treatment_col=\"\", batch_col=\"\"):\n",
    "    \"\"\"\n",
    "    add data validation code\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(sample_data_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:05:00.019218Z",
     "start_time": "2022-05-02T13:05:00.012134Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_correct(outDir, name,  r_path=\"../snippets/batchCorrect.R\"):\n",
    "    \"\"\"\n",
    "    Given count df only with good samples\n",
    "    sample data df (read in and validated somewhere else) with information about batches etc. \n",
    "    batch column name\n",
    "    \n",
    "    \"\"\"\n",
    "    count_path = outDir / f\"{name}_count.txt\"\n",
    "    batch_path = outDir / f\"{name}_batch.txt\"\n",
    "    cmd = f'Rscript {r_path} {count_path} {batch_path} {name} {outDir}'\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T08:58:40.878651Z",
     "start_time": "2022-04-29T08:58:40.874571Z"
    }
   },
   "source": [
    "## Run MAGeCK RRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:05:00.978413Z",
     "start_time": "2022-05-02T13:05:00.964458Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                         treatment='d1', control='d0', sampleID = 'sampleID'):\n",
    "    sDf = sampleData[sampleData[sampleID].isin(good_samples)]\n",
    "    controls = \",\".join(sDf[sDf[treat_col] == control][sampleID].unique())\n",
    "    treats = \",\".join(sDf[sDf[treat_col] == treatment][sampleID].unique())\n",
    "    return controls, treats\n",
    "\n",
    "\n",
    "def run_mageck(count_file, treated, controls, out_prefix, control_barcode_file):\n",
    "    \"\"\"\n",
    "    count file could be produced before or after batchcorrection\n",
    "    \n",
    "    \"\"\"\n",
    "    cmd = (f\"mageck test -k {count_file} -t {treated} \"\n",
    "          f\"-c {controls}  -n {out_prefix} \"  \n",
    "          f\"--control-sgrna {control_barcode_file}  --normcounts-to-file\")\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n",
    "\n",
    "def write_control_barcodes_to_file(wt_barcodes, name, outDir):\n",
    "    fname = outDir/f\"{name}_wt_barcodes.txt\"\n",
    "    with open(fname, \"w\") as fo:\n",
    "        for bc in wt_barcodes:\n",
    "            fo.write(f\"{bc}\\n\")\n",
    "    return fname\n",
    "    \n",
    "def process_mageck_matrix_file():\n",
    "    pass\n",
    "\n",
    "def run_mageck_mle(count_file, design_file, control_barcode_file, out_prefix):\n",
    "    cmd = (f\"mageck mle -k {count_file} -d {design_file} \"\n",
    "          f\" -n {out_prefix} --norm-method control --genes-varmodeling 0 \" # should be more?\n",
    "          f\"--permutation-round 2 \" # suggested 10\n",
    "          f\"--control-sgrna {control_barcode_file}\")\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:05:21.661652Z",
     "start_time": "2022-05-02T13:05:02.418415Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_count_file = countDir/\"library_11_1_mbarq_merged_counts.csv\"\n",
    "#control_file = root/\"controls_3col.csv\"\n",
    "control_file_short = root/\"controls_6barcodes.csv\"\n",
    "sample_data_file = root/configs['sampleData']\n",
    "name = \"library_11_1\"\n",
    "\n",
    "\n",
    "\n",
    "# Read in merged_count table and get sampleIDs\n",
    "counts, annotation_cols, sampleIDs = read_merged_count_file(merged_count_file)\n",
    "\n",
    "# Calculate cpms\n",
    "cpms = calculate_cpms(counts, annotation_cols, sampleIDs)\n",
    "\n",
    "# Read in control file\n",
    "cntrl_df, wt_barcodes = read_in_control_file(control_file_short)\n",
    "wt_df, full_control_df = get_control_counts(cntrl_df,  wt_barcodes, cpms, annotation_cols)\n",
    "\n",
    "# Figure out good samples\n",
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "\n",
    "# Read in sample data\n",
    "sampleData = read_in_sample_data(sample_data_file, good_samples)\n",
    "\n",
    "# subset df on only good samples and write out to file\n",
    "batch_file, count_file = prepare_mageck_dataset(counts, sampleData, wt_df.barcode.values, annotation_cols, good_samples, name, \n",
    "                           batch_col='experiment', treatment_col='day', outDir=scratchDir)\n",
    "\n",
    "# run batch correction\n",
    "batch_correct(scratchDir, name,  r_path=\"../snippets/batchCorrect.R\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:05:51.524029Z",
     "start_time": "2022-05-02T13:05:51.491415Z"
    }
   },
   "outputs": [],
   "source": [
    "%store good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:21:18.963464Z",
     "start_time": "2022-04-29T10:21:15.126677Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = write_control_barcodes_to_file(wt_barcodes, name, scratchDir)\n",
    "\n",
    "# run MAGeCK RRA for day 1\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d1', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d1\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:40:01.500312Z",
     "start_time": "2022-04-29T10:39:56.798713Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MAGeCK RRA for day 2\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d2', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d2\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:40:27.762394Z",
     "start_time": "2022-04-29T10:40:24.716086Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MAGeCK RRA for day 3\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d3', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d3\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:40:43.762834Z",
     "start_time": "2022-04-29T10:40:40.035043Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MAGeCK RRA for day 4\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d4', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d4\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:44:15.788683Z",
     "start_time": "2022-04-29T10:44:15.681262Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.concat([pd.read_table(scratchDir/f\"library_11_1-{i}.gene_summary.txt\").assign(treat=i) for i in ['d1','d2','d3',\n",
    "                                                                                               'd4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:47:45.798850Z",
     "start_time": "2022-04-29T10:47:45.252356Z"
    }
   },
   "outputs": [],
   "source": [
    "res[(res['pos|goodsgrna'] != 0) & (res['pos|fdr'] < 0.01)]['pos|lfc'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:31:16.642876Z",
     "start_time": "2022-04-29T10:31:16.616567Z"
    }
   },
   "outputs": [],
   "source": [
    "res[(res['neg|fdr'] < 0.01) & (res['neg|lfc'] < -0.5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:14:11.865464Z",
     "start_time": "2022-04-29T13:14:11.857585Z"
    }
   },
   "outputs": [],
   "source": [
    "fres = res[['id', 'num', 'neg|lfc', 'neg|fdr', 'pos|fdr', 'treat']]\n",
    "fres.columns = [annotation_cols[1], 'number_of_barcodes', 'LFC', 'neg_selection_fdr', 'pos_selection_fdr', 'contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:14:13.484720Z",
     "start_time": "2022-04-29T13:14:13.468068Z"
    }
   },
   "outputs": [],
   "source": [
    "fres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:18:12.996200Z",
     "start_time": "2022-04-29T13:18:12.910443Z"
    }
   },
   "outputs": [],
   "source": [
    "fres.to_csv(scratchDir/'library_11_1_rra_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:03:46.158356Z",
     "start_time": "2022-04-29T13:03:45.977619Z"
    }
   },
   "outputs": [],
   "source": [
    "%ls /nfs/nas22/fs2202/biol_micro_bioinf_nccr/hardt/nguyenb/tnseq/scratch/04_22/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T12:44:33.047322Z",
     "start_time": "2022-04-29T12:44:33.033976Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix = (pd.get_dummies(sampleData[sampleData.sampleID.isin(good_samples)][['sampleID', 'day']]\n",
    "                         .set_index('sampleID'))\n",
    "         .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T12:45:11.969722Z",
     "start_time": "2022-04-29T12:45:11.877902Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix.to_csv(scratchDir/'design_matrix.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:03:26.983840Z",
     "start_time": "2022-04-29T12:56:07.533050Z"
    }
   },
   "outputs": [],
   "source": [
    "run_mageck_mle(count_file2, scratchDir/'design_matrix.tsv', fname, scratchDir/\"mle_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:04:08.347067Z",
     "start_time": "2022-04-29T13:04:08.291095Z"
    }
   },
   "outputs": [],
   "source": [
    "mle_res = pd.read_table(scratchDir/\"mle_test.gene_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:10:34.577790Z",
     "start_time": "2022-04-29T13:10:34.552251Z"
    }
   },
   "outputs": [],
   "source": [
    "mle_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:11:15.222745Z",
     "start_time": "2022-04-29T13:11:15.198376Z"
    }
   },
   "outputs": [],
   "source": [
    "mle_res[(mle_res['day_d1|wald-fdr'] < 0.05) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each library:\n",
    "library='library_12_2'\n",
    "meta = meat[meat.library == library]\n",
    "c = all_contrasts[library]\n",
    "\n",
    "\n",
    "def mageck_library(library, meta, outDir, contrasts, control_barcode_file, batch_corr=True, batch_col='batch'):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. Check if batch correction is needed, run if yes -> different count file as input for mageck\n",
    "    2. For each contrast check if threr are samples, run mageck\n",
    "    3. Concatenate results for multiple days\n",
    "\n",
    "    \"\"\"\n",
    "    print(meta[batch_col].nunique())\n",
    "    if batch_corr is True and meta[batch_col].nunique() > 1:\n",
    "        batch_correct(outDir, library,  r_path=\"./batchCorrect.R\")\n",
    "        count_file = outDir/f\"{library}_count_batchcorrected.txt\"\n",
    "    else:\n",
    "        count_file = outDir/f\"{library}_count.txt\"\n",
    "        \n",
    "    result_dfs = []\n",
    "    for contrast, samples in contrasts.items():\n",
    "        print(contrast)\n",
    "        if len(samples[0]) == 0 or len(samples[1]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            treated = samples[1] \n",
    "            controls = samples[0]\n",
    "        out_prefix = outDir/f\"{library}-{contrast}\"\n",
    "        run_mageck(count_file, treated, controls, out_prefix, control_barcode_file)\n",
    "        res = pd.read_table(f'{out_prefix}.gene_summary.txt').assign(contrast=contrast)\n",
    "        result_dfs.append(res)\n",
    "    results = pd.concat(result_dfs).assign(library=library)\n",
    "    return results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
