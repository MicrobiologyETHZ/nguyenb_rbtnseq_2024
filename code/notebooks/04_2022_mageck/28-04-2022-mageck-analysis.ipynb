{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:17.045715Z",
     "start_time": "2022-05-04T10:58:13.470922Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../snippets/basic_settings.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import yaml\n",
    "\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 12)\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['text.usetex'] = False  # True activates latex output in fonts!\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.serif'] = \"cm\"\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:19.198012Z",
     "start_time": "2022-05-04T10:58:19.192554Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:20.233066Z",
     "start_time": "2022-05-04T10:58:20.221945Z"
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"../nguyenb_config.yaml\"\n",
    "with open(config_file) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    configs = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:20.904006Z",
     "start_time": "2022-05-04T10:58:20.898840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run on server:\n",
    "root = Path(configs['root']['server'])\n",
    "scratchDir = Path(configs['scratchDir']['server'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:21.942207Z",
     "start_time": "2022-05-04T10:58:21.936938Z"
    }
   },
   "outputs": [],
   "source": [
    "mapDir = root/configs['mapDir']\n",
    "countDir = root/configs['libraryCountsDir']\n",
    "resultDir = root/configs['resultDir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:23.600319Z",
     "start_time": "2022-05-04T10:58:23.593917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def run_command(args):\n",
    "    \"\"\"Run command, transfer stdout/stderr\"\"\"\n",
    "    result = subprocess.run(args)\n",
    "    try:\n",
    "        result.check_returncode()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data \n",
    "- Using data from library_11_1 as a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:30:41.195707Z",
     "start_time": "2022-05-04T11:30:41.186863Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_merged_count_file(merged_count_file):\n",
    "    counts = pd.read_csv(merged_count_file)\n",
    "    annotation_cols = list(counts.columns[0:2])\n",
    "    sampleIDs = list(counts.columns[2:])\n",
    "    return counts, annotation_cols, sampleIDs\n",
    "\n",
    "\n",
    "def calculate_cpms(merged_df, annotation_cols, sampleIDs):\n",
    "    merged_df = merged_df[merged_df.sum(axis=1, numeric_only=True) > 10]\n",
    "    # Normalized for library depth and log transform\n",
    "    cpms = merged_df.copy().set_index(list(annotation_cols))\n",
    "    cpms = np.log2(cpms/cpms.sum()*1000000 +0.5).reset_index()\n",
    "    return cpms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:04:17.133018Z",
     "start_time": "2022-04-28T15:04:17.118967Z"
    }
   },
   "source": [
    "## Extract counts for control barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:35.209176Z",
     "start_time": "2022-05-04T10:58:35.196304Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_in_control_file(control_file: Union[str, Path]):\n",
    "    \"\"\"\n",
    "    Control file: No header\n",
    "    \n",
    "    [barcode],[conc],[phenotype]\n",
    "    \n",
    "    1. Check that the first column contains barcodes\n",
    "    2. Check that second column is numeric -> should contain concentrations\n",
    "    3. If there is a thrid column it should be string, and at least one should be ['wt', 'WT', 'wildtype']\n",
    "    \n",
    "    \"\"\"\n",
    "    cntrl_df = pd.read_csv(control_file, header=None)\n",
    "    num_cols = cntrl_df.shape[1]\n",
    "    \n",
    "    # Add column validation code here\n",
    "    \n",
    "    col_names = ['barcode', 'concentration', 'genotype']\n",
    "    cntrl_df.columns = col_names[0:num_cols]\n",
    "    \n",
    "    if num_cols == 3:\n",
    "        if any(cntrl_df.genotype.isin(['wt', 'WT', 'wildtype'])):\n",
    "            wt_barcodes = cntrl_df[cntrl_df.genotype.isin(['wt', 'WT', 'wildtype'])].barcode.values\n",
    "        else:\n",
    "            wt_barcodes = []\n",
    "    else:\n",
    "        wt_barcodes = cntrl_df.barcode.values\n",
    "    return cntrl_df, wt_barcodes\n",
    "\n",
    "\n",
    "def get_control_counts(cntrl_df: pd.DataFrame, wt_barcodes: List, counts_df: pd.DataFrame, \n",
    "                      annotations_col: List) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    counts_df: \n",
    "    barcode,geneName,sample1,sample2\n",
    "    \n",
    "    Merge left, convert NA to 0 \n",
    "    return merged data frame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_cols = cntrl_df.shape[1]\n",
    "    if annotations_col[0] != 'barcode':\n",
    "        counts_df = counts_df.rename({annotations_col[0]: 'barcode'}, axis=1)\n",
    "    # Add column validation for counts_df\n",
    "    fdf = cntrl_df.merge(counts_df, how='left', on='barcode').fillna(0)\n",
    "    if len(wt_barcodes) > 0:\n",
    "        wt_df = fdf[fdf.barcode.isin(wt_barcodes)]\n",
    "    else:\n",
    "        wt_df = pd.DataFrame()\n",
    "    return wt_df, fdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:37.804478Z",
     "start_time": "2022-05-04T10:58:37.796191Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_correlation(control_df: pd.DataFrame, sampleIDs: List, cutoff: float=0.8):\n",
    "    \"\"\"\n",
    "    Given a data frame with a 'concentration' column and sampleID (normalised) counts + list of sampleIDs, \n",
    "    calculate correlation between concentration \n",
    "    return a list of 'good samples', i.e. passing the cutoff\n",
    "    \n",
    "    Assert concentration column is present\n",
    "    Assert sampleIDs are in control_df columns\n",
    "    \"\"\"\n",
    "    concentrations = np.log2(control_df.concentration)\n",
    "    samples = control_df[sampleIDs]\n",
    "    corr_df = pd.DataFrame(samples.corrwith(concentrations), columns=['R'])\n",
    "    corr_df[\"R2\"] = corr_df.R**2\n",
    "    good_samples = list(corr_df[corr_df.R2 > cutoff].index)\n",
    "    return corr_df, good_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:40.754992Z",
     "start_time": "2022-05-04T10:58:40.750193Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_correlation_plots(control_df, sampleIDs):\n",
    "    \"\"\"\n",
    "    given a complete control_df, draw correlation plot for each sampleID for each genotype\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:44.249244Z",
     "start_time": "2022-05-04T10:58:44.244766Z"
    }
   },
   "outputs": [],
   "source": [
    "not_found_in_dnaid1315 = ['AACAACACGGTAAGCAA', 'AGAATGACCCGGAGGCT', 'AGTCATCGATGCTATAT', 'CCGACGACTGATTGTCC',\n",
    "           'CTACGACAGGGACTTAA', 'GTGTATAGCAGGAACCC', 'GTGTATAGCAGGAACCC', 'TAAGTCCGGGCTAAGTC',\n",
    "           'TATAACACCCCCGATTC', 'TCTCACGCAGCGTTTCG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:04:56.586464Z",
     "start_time": "2022-05-02T13:04:56.581923Z"
    }
   },
   "outputs": [],
   "source": [
    "# cdf1 = cdf[[1]]\n",
    "# cdf1.to_csv(root/\"controls_1col.csv\", index=False, header=None)\n",
    "# cdf2 = cdf[[1,3]]\n",
    "# cdf2.to_csv(root/\"controls_2col.csv\", index=False,header=None)\n",
    "# cdf3 = cdf[[1,3,2]]\n",
    "# cdf3.to_csv(root/\"controls_3col.csv\", index=False,header=None)\n",
    "#wt_df[['barcode', 'concentration']].to_csv(root/\"controls_6barcodes.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAGeCK Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare MAGeCK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:47.315296Z",
     "start_time": "2022-05-04T10:58:47.304232Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_mageck_dataset(counts_df, sampleData, control_barcodes, annotation_cols, good_samples, name, \n",
    "                           batch_col, treatment_col, outDir):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Assume the first column of sampleData contains sampleIDs.\n",
    "    Assume second has geneName\n",
    "    The rest are raw counts for samples in sampleIDs.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    batch_file = outDir/f\"{name}_batch.txt\"\n",
    "    count_file = outDir/f\"{name}_count.txt\"\n",
    "    sampleID_col = sampleData.columns[0]\n",
    "\n",
    "    batch_df = (sampleData[sampleData[sampleID_col].isin(good_samples)]\n",
    "                [[sampleID_col, batch_col, treatment_col]]\n",
    "                .sort_values([treatment_col, batch_col]))\n",
    "\n",
    "    batch_df.to_csv(batch_file, index=False, sep='\\t')\n",
    "    magDf = counts_df[annotation_cols + good_samples].copy()\n",
    "    magDf.loc[magDf[annotation_cols[0]].isin(control_barcodes), annotation_cols[1]] = 'control'\n",
    "    magDf = magDf.dropna(subset=annotation_cols).fillna(0)\n",
    "    magDf.to_csv(count_file, index=False, sep='\\t')\n",
    "    return batch_file, count_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MAGeCK batch correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:48.724706Z",
     "start_time": "2022-05-04T10:58:48.719343Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_in_sample_data(sample_data_file, sampleIDs, treatment_col=\"\", batch_col=\"\"):\n",
    "    \"\"\"\n",
    "    add data validation code\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(sample_data_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:49.341539Z",
     "start_time": "2022-05-04T10:58:49.334997Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_correct(outDir, name,  r_path=\"../snippets/batchCorrect.R\"):\n",
    "    \"\"\"\n",
    "    Given count df only with good samples\n",
    "    sample data df (read in and validated somewhere else) with information about batches etc. \n",
    "    batch column name\n",
    "    \n",
    "    \"\"\"\n",
    "    count_path = outDir / f\"{name}_count.txt\"\n",
    "    batch_path = outDir / f\"{name}_batch.txt\"\n",
    "    cmd = f'Rscript {r_path} {count_path} {batch_path} {name} {outDir}'\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T08:58:40.878651Z",
     "start_time": "2022-04-29T08:58:40.874571Z"
    }
   },
   "source": [
    "## Run MAGeCK RRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:58:50.399313Z",
     "start_time": "2022-05-04T10:58:50.387219Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                         treatment='d1', control='d0', sampleID = 'sampleID'):\n",
    "    sDf = sampleData[sampleData[sampleID].isin(good_samples)]\n",
    "    controls = \",\".join(sDf[sDf[treat_col] == control][sampleID].unique())\n",
    "    treats = \",\".join(sDf[sDf[treat_col] == treatment][sampleID].unique())\n",
    "    return controls, treats\n",
    "\n",
    "\n",
    "def run_mageck(count_file, treated, controls, out_prefix, control_barcode_file):\n",
    "    \"\"\"\n",
    "    count file could be produced before or after batchcorrection\n",
    "    \n",
    "    \"\"\"\n",
    "    cmd = (f\"mageck test -k {count_file} -t {treated} \"\n",
    "          f\"-c {controls}  -n {out_prefix} \"  \n",
    "          f\"--control-sgrna {control_barcode_file}  --normcounts-to-file\")\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n",
    "\n",
    "def write_control_barcodes_to_file(wt_barcodes, name, outDir):\n",
    "    fname = outDir/f\"{name}_wt_barcodes.txt\"\n",
    "    with open(fname, \"w\") as fo:\n",
    "        for bc in wt_barcodes:\n",
    "            fo.write(f\"{bc}\\n\")\n",
    "    return fname\n",
    "    \n",
    "def process_mageck_matrix_file():\n",
    "    pass\n",
    "\n",
    "def run_mageck_mle(count_file, design_file, control_barcode_file, out_prefix):\n",
    "    cmd = (f\"mageck mle -k {count_file} -d {design_file} \"\n",
    "          f\" -n {out_prefix} --norm-method control --genes-varmodeling 0 \" # should be more?\n",
    "          f\"--permutation-round 2 \" # suggested 10\n",
    "          f\"--control-sgrna {control_barcode_file}\")\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:02:29.398348Z",
     "start_time": "2022-05-04T11:02:29.392539Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_count_file = countDir/\"library_11_1_mbarq_merged_counts.csv\"\n",
    "control_file = root/\"controls_3col.csv\"\n",
    "control_file_short = root/\"controls_6barcodes.csv\"\n",
    "sample_data_file = root/configs['sampleData']\n",
    "name = \"library_11_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:24:05.625892Z",
     "start_time": "2022-05-04T11:24:05.610535Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_samples(merged_count_file, control_file):\n",
    "    # Read in merged_count table and get sampleIDs\n",
    "    counts, annotation_cols, sampleIDs = read_merged_count_file(merged_count_file)\n",
    "    # Calculate cpms\n",
    "    cpms = calculate_cpms(counts, annotation_cols, sampleIDs)\n",
    "\n",
    "    # Read in control file\n",
    "    cntrl_df, wt_barcodes = read_in_control_file(control_file)\n",
    "    wt_df, full_control_df = get_control_counts(cntrl_df,  wt_barcodes, cpms, annotation_cols)\n",
    "    return counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df\n",
    "    \n",
    "    \n",
    "\n",
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:09:07.740994Z",
     "start_time": "2022-05-04T12:09:07.716884Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, name, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 ):\n",
    "    \n",
    "    # Read in sample data\n",
    "    sampleData = read_in_sample_data(sample_data_file, good_samples)\n",
    "    wt_barcodes = wt_df.barcode.values\n",
    "    # subset df on only good samples and write out to file\n",
    "    batch_file, count_file = prepare_mageck_dataset(counts, sampleData, wt_barcodes, \n",
    "                                                    annotation_cols, good_samples, name, \n",
    "                                                    batch_col,treatment_col, outDir)\n",
    "\n",
    "    # run batch correction\n",
    "    batch_correct(scratchDir, name,  r_path=\"../snippets/batchCorrect.R\")\n",
    "    \n",
    "    fname = write_control_barcodes_to_file(wt_barcodes, name, scratchDir)\n",
    "\n",
    "    # run MAGeCK RRA for day 1\n",
    "    contrasts_ran = []\n",
    "    for contrast in contrasts:\n",
    "        controls, treat = get_contrast_samples(sampleData, good_samples, treatment_col, \n",
    "                                               contrast, baseline, sampleID)\n",
    "        count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "        if len(treat) > 0 and len(controls) > 0:\n",
    "            run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-{contrast}\", fname)\n",
    "            contrasts_ran.append(contrast)\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.concat([pd.read_table(scratchDir/f\"{name}-{i}.gene_summary.txt\").assign(treat=i) \n",
    "                     for i in contrasts_ran])\n",
    "    fres = res[['id', 'num', 'neg|lfc', 'neg|fdr', 'pos|fdr', 'treat']]\n",
    "    fres.columns = [annotation_cols[1], 'number_of_barcodes', 'LFC', 'neg_selection_fdr', 'pos_selection_fdr', 'contrast']\n",
    "    fres.to_csv(scratchDir/f'{name}_rra_results.csv')\n",
    "    return fres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:05:21.661652Z",
     "start_time": "2022-05-02T13:05:02.418415Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read in merged_count table and get sampleIDs\n",
    "counts, annotation_cols, sampleIDs = read_merged_count_file(merged_count_file)\n",
    "\n",
    "# Calculate cpms\n",
    "cpms = calculate_cpms(counts, annotation_cols, sampleIDs)\n",
    "\n",
    "# Read in control file\n",
    "cntrl_df, wt_barcodes = read_in_control_file(control_file_short)\n",
    "wt_df, full_control_df = get_control_counts(cntrl_df,  wt_barcodes, cpms, annotation_cols)\n",
    "\n",
    "# Figure out good samples\n",
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "\n",
    "# Read in sample data\n",
    "sampleData = read_in_sample_data(sample_data_file, good_samples)\n",
    "\n",
    "# subset df on only good samples and write out to file\n",
    "batch_file, count_file = prepare_mageck_dataset(counts, sampleData, wt_df.barcode.values, annotation_cols, good_samples, name, \n",
    "                           batch_col='experiment', treatment_col='day', outDir=scratchDir)\n",
    "\n",
    "# run batch correction\n",
    "batch_correct(scratchDir, name,  r_path=\"../snippets/batchCorrect.R\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:21:18.963464Z",
     "start_time": "2022-04-29T10:21:15.126677Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = write_control_barcodes_to_file(wt_barcodes, name, scratchDir)\n",
    "\n",
    "# run MAGeCK RRA for day 1\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d1', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d1\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T13:05:51.524029Z",
     "start_time": "2022-05-02T13:05:51.491415Z"
    }
   },
   "outputs": [],
   "source": [
    "%store good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:40:01.500312Z",
     "start_time": "2022-04-29T10:39:56.798713Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MAGeCK RRA for day 2\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d2', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d2\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:40:27.762394Z",
     "start_time": "2022-04-29T10:40:24.716086Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MAGeCK RRA for day 3\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d3', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d3\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:40:43.762834Z",
     "start_time": "2022-04-29T10:40:40.035043Z"
    }
   },
   "outputs": [],
   "source": [
    "# run MAGeCK RRA for day 4\n",
    "\n",
    "controls, treat = get_contrast_samples(sampleData, good_samples, treat_col = 'day', \n",
    "                                       treatment='d4', control='d0', sampleID = 'sampleID')\n",
    "count_file2 = count_file.with_suffix('.batchcorrected.txt')\n",
    "run_mageck(count_file2, treat, controls, scratchDir/f\"{name}-d4\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:44:15.788683Z",
     "start_time": "2022-04-29T10:44:15.681262Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.concat([pd.read_table(scratchDir/f\"library_11_1-{i}.gene_summary.txt\").assign(treat=i) for i in ['d1','d2','d3',\n",
    "                                                                                               'd4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:47:45.798850Z",
     "start_time": "2022-04-29T10:47:45.252356Z"
    }
   },
   "outputs": [],
   "source": [
    "res[(res['pos|goodsgrna'] != 0) & (res['pos|fdr'] < 0.01)]['pos|lfc'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T10:31:16.642876Z",
     "start_time": "2022-04-29T10:31:16.616567Z"
    }
   },
   "outputs": [],
   "source": [
    "res[(res['neg|fdr'] < 0.01) & (res['neg|lfc'] < -0.5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:14:11.865464Z",
     "start_time": "2022-04-29T13:14:11.857585Z"
    }
   },
   "outputs": [],
   "source": [
    "fres = res[['id', 'num', 'neg|lfc', 'neg|fdr', 'pos|fdr', 'treat']]\n",
    "fres.columns = [annotation_cols[1], 'number_of_barcodes', 'LFC', 'neg_selection_fdr', 'pos_selection_fdr', 'contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:14:13.484720Z",
     "start_time": "2022-04-29T13:14:13.468068Z"
    }
   },
   "outputs": [],
   "source": [
    "fres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:18:12.996200Z",
     "start_time": "2022-04-29T13:18:12.910443Z"
    }
   },
   "outputs": [],
   "source": [
    "fres.to_csv(scratchDir/'library_11_1_rra_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at controls across libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:03:36.892961Z",
     "start_time": "2022-05-04T11:03:36.879195Z"
    }
   },
   "outputs": [],
   "source": [
    "# There are 12 libraries:\n",
    "sampleData = pd.read_csv(sample_data_file)\n",
    "libraries = sampleData[sampleData.library != 'LibraryA'].library.unique()\n",
    "libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 14_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:31:14.020898Z",
     "start_time": "2022-05-04T11:31:13.957762Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "lib_file = countDir/\"library_14_1_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == 'library_14_1']\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:31:14.920818Z",
     "start_time": "2022-05-04T11:31:14.904189Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:32:15.293130Z",
     "start_time": "2022-05-04T11:32:15.280083Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:24:38.855954Z",
     "start_time": "2022-05-04T11:24:38.845686Z"
    }
   },
   "outputs": [],
   "source": [
    "lib14_missing = list(wt_df[wt_df.dnaid1428_117 == 0].barcode.sort_values().values)\n",
    "lib14_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:25:45.798642Z",
     "start_time": "2022-05-04T11:25:45.782335Z"
    }
   },
   "outputs": [],
   "source": [
    "lib14_present = wt_df[wt_df.dnaid1428_117 > 0]\n",
    "corr_df, good_samples = calculate_correlation(lib14_present, sampleIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:25:48.079655Z",
     "start_time": "2022-05-04T11:25:48.068367Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:25:52.520668Z",
     "start_time": "2022-05-04T11:25:52.514574Z"
    }
   },
   "outputs": [],
   "source": [
    "good_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library 14_1 did not have any samples passing quality control\n",
    "dnaid1428 seems to be missing 9 barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 15_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:52:35.409062Z",
     "start_time": "2022-05-04T11:52:35.232219Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_15_1'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnaid2025 and dnaid2026 have all 15 control barcodes\n",
    "\n",
    "None of the samples in dnaid1428 has passed the qc no matter which barcodes are used for the controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:52:36.230664Z",
     "start_time": "2022-05-04T11:52:36.213135Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:52:39.211817Z",
     "start_time": "2022-05-04T11:52:39.189682Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:40:51.059577Z",
     "start_time": "2022-05-04T11:40:51.041684Z"
    }
   },
   "outputs": [],
   "source": [
    "dnaid1428 = wt_df[['barcode', 'concentration']+[c for c in wt_df.columns if 'dnaid1428' in c]]\n",
    "dnaid1428 = dnaid1428[dnaid1428.dnaid1428_124 > -1]\n",
    "good_samples1428 = calculate_correlation(dnaid1428, [c for c in wt_df.columns if 'dnaid1428' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:53:12.121609Z",
     "start_time": "2022-05-04T11:52:47.747616Z"
    }
   },
   "outputs": [],
   "source": [
    "res15_1 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:53:44.060892Z",
     "start_time": "2022-05-04T11:53:44.041144Z"
    }
   },
   "outputs": [],
   "source": [
    "res15_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:52:19.505140Z",
     "start_time": "2022-05-04T11:52:19.478163Z"
    }
   },
   "outputs": [],
   "source": [
    "%store -r maDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:55:15.438056Z",
     "start_time": "2022-05-04T11:55:15.423831Z"
    }
   },
   "outputs": [],
   "source": [
    "maDf15 = maDf[maDf.library == 'library_15_1']\n",
    "maDf15.columns = ['Name', 'neg|fdr', 'neg|lfc', 'pos|fdr', 'contrast', 'library', 'fdr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 13_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:08:34.043203Z",
     "start_time": "2022-05-04T12:08:33.867629Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_13_2'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnaid1428 and dnaid1457 also seem to be missing some controls. dnaid2023 and dnaid2024 look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:08:35.346578Z",
     "start_time": "2022-05-04T12:08:35.331035Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:08:35.971754Z",
     "start_time": "2022-05-04T12:08:35.946876Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:08:36.683172Z",
     "start_time": "2022-05-04T12:08:36.676922Z"
    }
   },
   "outputs": [],
   "source": [
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:09:33.995401Z",
     "start_time": "2022-05-04T12:09:12.624200Z"
    }
   },
   "outputs": [],
   "source": [
    "res13_2 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 9_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:11:38.215430Z",
     "start_time": "2022-05-04T12:11:37.995449Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_9_1'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnaid1429 also missing control barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:11:46.966585Z",
     "start_time": "2022-05-04T12:11:46.949269Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:12:43.355788Z",
     "start_time": "2022-05-04T12:12:43.332170Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:13:25.242728Z",
     "start_time": "2022-05-04T12:13:05.518289Z"
    }
   },
   "outputs": [],
   "source": [
    "res9_1 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:13:31.513950Z",
     "start_time": "2022-05-04T12:13:31.499353Z"
    }
   },
   "outputs": [],
   "source": [
    "res9_1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:14:16.264283Z",
     "start_time": "2022-05-04T12:14:15.990120Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_10_1'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnaid15 and 16 are fine\n",
    "danid1429 not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:14:17.493315Z",
     "start_time": "2022-05-04T12:14:17.477680Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:15:01.368097Z",
     "start_time": "2022-05-04T12:15:01.333288Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:16:11.166554Z",
     "start_time": "2022-05-04T12:15:26.351388Z"
    }
   },
   "outputs": [],
   "source": [
    "res10_1 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:30:48.967939Z",
     "start_time": "2022-05-04T12:30:48.958739Z"
    }
   },
   "outputs": [],
   "source": [
    "genes = list(res10_1[(res10_1.contrast == 'd1') & \n",
    "        (res10_1.LFC < -0.5 ) & \n",
    "        (res10_1.neg_selection_fdr<0.01)].Name.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 11_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:32:07.445538Z",
     "start_time": "2022-05-04T12:32:07.336856Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_11_2'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnaid1457 is still crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:32:08.035044Z",
     "start_time": "2022-05-04T12:32:08.019627Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:32:08.701543Z",
     "start_time": "2022-05-04T12:32:08.677510Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:32:38.211635Z",
     "start_time": "2022-05-04T12:32:09.588631Z"
    }
   },
   "outputs": [],
   "source": [
    "res11_2 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:32:55.000479Z",
     "start_time": "2022-05-04T12:32:54.984309Z"
    }
   },
   "outputs": [],
   "source": [
    "res11_2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 12_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:33:08.434581Z",
     "start_time": "2022-05-04T12:33:08.189039Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_12_1'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:33:20.154389Z",
     "start_time": "2022-05-04T12:33:20.139582Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:33:42.258799Z",
     "start_time": "2022-05-04T12:33:42.231582Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:34:24.256795Z",
     "start_time": "2022-05-04T12:34:00.732579Z"
    }
   },
   "outputs": [],
   "source": [
    "res12_1 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:34:29.030355Z",
     "start_time": "2022-05-04T12:34:29.013326Z"
    }
   },
   "outputs": [],
   "source": [
    "res12_1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 12_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:34:52.173892Z",
     "start_time": "2022-05-04T12:34:51.661948Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_12_2'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:34:59.469239Z",
     "start_time": "2022-05-04T12:34:59.442056Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:35:26.703044Z",
     "start_time": "2022-05-04T12:35:26.666404Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:36:14.587067Z",
     "start_time": "2022-05-04T12:35:48.109041Z"
    }
   },
   "outputs": [],
   "source": [
    "res12_2 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:36:14.599494Z",
     "start_time": "2022-05-04T12:36:14.589211Z"
    }
   },
   "outputs": [],
   "source": [
    "res12_2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 13_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:36:51.025985Z",
     "start_time": "2022-05-04T12:36:50.790275Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_13_1'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:36:58.846717Z",
     "start_time": "2022-05-04T12:36:58.829996Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:37:23.427500Z",
     "start_time": "2022-05-04T12:37:23.399981Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:38:05.978448Z",
     "start_time": "2022-05-04T12:37:43.794833Z"
    }
   },
   "outputs": [],
   "source": [
    "res13_1 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:38:11.282813Z",
     "start_time": "2022-05-04T12:38:11.265462Z"
    }
   },
   "outputs": [],
   "source": [
    "res13_1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:39:03.403300Z",
     "start_time": "2022-05-04T12:39:02.896844Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_10_2'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:39:14.194564Z",
     "start_time": "2022-05-04T12:39:14.178331Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:39:31.343531Z",
     "start_time": "2022-05-04T12:39:31.311948Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:40:20.227765Z",
     "start_time": "2022-05-04T12:39:51.935714Z"
    }
   },
   "outputs": [],
   "source": [
    "res10_2 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:40:21.536411Z",
     "start_time": "2022-05-04T12:40:21.519367Z"
    }
   },
   "outputs": [],
   "source": [
    "res10_2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 14_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:42:16.557246Z",
     "start_time": "2022-05-04T12:42:16.247140Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData = pd.read_csv(sample_data_file)\n",
    "library = 'library_14_2'\n",
    "lib_file = countDir/f\"{library}_mbarq_merged_counts.csv\"\n",
    "sampleData = sampleData[sampleData.library == library]\n",
    "counts, annotation_cols, sampleIDs, cpms, wt_df, full_control_df = clean_samples(lib_file, control_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:42:26.308750Z",
     "start_time": "2022-05-04T12:42:26.289249Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_df[list(sampleData[sampleData.tissue == 'inoculum'].sampleID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:42:42.866450Z",
     "start_time": "2022-05-04T12:42:42.838159Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_df, good_samples = calculate_correlation(wt_df, sampleIDs)\n",
    "good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:43:30.929207Z",
     "start_time": "2022-05-04T12:43:04.546371Z"
    }
   },
   "outputs": [],
   "source": [
    "res14_2 = run_analysis(counts, sample_data_file, good_samples, wt_df, \n",
    "                 annotation_cols, library, batch_col='experiment', treatment_col='day', \n",
    "                 contrasts = ['d1', 'd2', 'd3', 'd4'], baseline='d0',\n",
    "                 sampleID='sampleID',\n",
    "                 outDir=scratchDir\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T12:43:40.957449Z",
     "start_time": "2022-05-04T12:43:40.940163Z"
    }
   },
   "outputs": [],
   "source": [
    "res14_2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T12:44:33.047322Z",
     "start_time": "2022-04-29T12:44:33.033976Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix = (pd.get_dummies(sampleData[sampleData.sampleID.isin(good_samples)][['sampleID', 'day']]\n",
    "                         .set_index('sampleID'))\n",
    "         .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T12:45:11.969722Z",
     "start_time": "2022-04-29T12:45:11.877902Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix.to_csv(scratchDir/'design_matrix.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:03:26.983840Z",
     "start_time": "2022-04-29T12:56:07.533050Z"
    }
   },
   "outputs": [],
   "source": [
    "run_mageck_mle(count_file2, scratchDir/'design_matrix.tsv', fname, scratchDir/\"mle_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:04:08.347067Z",
     "start_time": "2022-04-29T13:04:08.291095Z"
    }
   },
   "outputs": [],
   "source": [
    "mle_res = pd.read_table(scratchDir/\"mle_test.gene_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:10:34.577790Z",
     "start_time": "2022-04-29T13:10:34.552251Z"
    }
   },
   "outputs": [],
   "source": [
    "mle_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T13:11:15.222745Z",
     "start_time": "2022-04-29T13:11:15.198376Z"
    }
   },
   "outputs": [],
   "source": [
    "mle_res[(mle_res['day_d1|wald-fdr'] < 0.05) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each library:\n",
    "library='library_12_2'\n",
    "meta = meat[meat.library == library]\n",
    "c = all_contrasts[library]\n",
    "\n",
    "\n",
    "def mageck_library(library, meta, outDir, contrasts, control_barcode_file, batch_corr=True, batch_col='batch'):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. Check if batch correction is needed, run if yes -> different count file as input for mageck\n",
    "    2. For each contrast check if threr are samples, run mageck\n",
    "    3. Concatenate results for multiple days\n",
    "\n",
    "    \"\"\"\n",
    "    print(meta[batch_col].nunique())\n",
    "    if batch_corr is True and meta[batch_col].nunique() > 1:\n",
    "        batch_correct(outDir, library,  r_path=\"./batchCorrect.R\")\n",
    "        count_file = outDir/f\"{library}_count_batchcorrected.txt\"\n",
    "    else:\n",
    "        count_file = outDir/f\"{library}_count.txt\"\n",
    "        \n",
    "    result_dfs = []\n",
    "    for contrast, samples in contrasts.items():\n",
    "        print(contrast)\n",
    "        if len(samples[0]) == 0 or len(samples[1]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            treated = samples[1] \n",
    "            controls = samples[0]\n",
    "        out_prefix = outDir/f\"{library}-{contrast}\"\n",
    "        run_mageck(count_file, treated, controls, out_prefix, control_barcode_file)\n",
    "        res = pd.read_table(f'{out_prefix}.gene_summary.txt').assign(contrast=contrast)\n",
    "        result_dfs.append(res)\n",
    "    results = pd.concat(result_dfs).assign(library=library)\n",
    "    return results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
