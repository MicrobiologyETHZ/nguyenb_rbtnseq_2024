{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T14:58:20.597481Z",
     "start_time": "2022-04-28T14:58:17.349500Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../snippets/basic_settings.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import yaml\n",
    "\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 12)\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['text.usetex'] = False  # True activates latex output in fonts!\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.serif'] = \"cm\"\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:21:43.823884Z",
     "start_time": "2022-04-28T15:21:43.819328Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T14:58:50.685185Z",
     "start_time": "2022-04-28T14:58:50.673420Z"
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"../nguyenb_config.yaml\"\n",
    "with open(config_file) as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    configs = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T14:58:52.178948Z",
     "start_time": "2022-04-28T14:58:52.174149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run on server:\n",
    "root = Path(configs['root']['server'])\n",
    "scratchDir = configs['scratchDir']['server']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T14:59:25.647637Z",
     "start_time": "2022-04-28T14:59:25.634629Z"
    }
   },
   "outputs": [],
   "source": [
    "mapDir = root/configs['mapDir']\n",
    "countDir = root/configs['libraryCountsDir']\n",
    "resultDir = root/configs['resultDir']\n",
    "sampleData = pd.read_csv(root/configs['sampleData'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data \n",
    "- Using data from library_11_1 as a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:46:56.057647Z",
     "start_time": "2022-04-28T18:46:55.877237Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = pd.read_csv(countDir/\"library_11_1_mbarq_merged_counts.csv\")\n",
    "countsFilt = counts[counts.sum(axis=1, numeric_only=True) > 10]\n",
    "\n",
    "\n",
    "# Normalized for library depth and log transform\n",
    "annotation_cols = list(countsFilt.columns[0:2])\n",
    "sampleIDs = list(countsFilt.columns[2:])\n",
    "cpms = countsFilt.copy().set_index(list(annotation_cols))\n",
    "cpms = np.log2(cpms/cpms.sum()*1000000 +0.5).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:32:54.225669Z",
     "start_time": "2022-04-28T18:32:54.191673Z"
    }
   },
   "outputs": [],
   "source": [
    "cpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T16:43:14.933558Z",
     "start_time": "2022-04-28T16:43:14.910807Z"
    }
   },
   "outputs": [],
   "source": [
    "countsFilt.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:04:17.133018Z",
     "start_time": "2022-04-28T15:04:17.118967Z"
    }
   },
   "source": [
    "## Extract counts for control barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:47:04.724139Z",
     "start_time": "2022-04-28T18:47:04.712911Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_control_counts(control_file: Union[str, Path], counts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Control file: No header\n",
    "    \n",
    "    [barcode],[conc],[phenotype]\n",
    "    \n",
    "    1. Check that the first column contains barcodes\n",
    "    2. Check that second column is numeric -> should contain concentrations\n",
    "    3. If there is a thrid column it should be string, and at least one should be ['wt', 'WT', 'wildtype']\n",
    "    \n",
    "    counts_df: \n",
    "    barcode,geneName,sample1,sample2\n",
    "    \n",
    "    Merge left, convert NA to 0 \n",
    "    return merged data frame\n",
    "    \n",
    "    \"\"\"\n",
    "    cntrl_df = pd.read_csv(control_file, header=None)\n",
    "    num_cols = cntrl_df.shape[1]\n",
    "    \n",
    "    # Add column validation code here\n",
    "    col_names = ['barcode', 'concentration', 'genotype']\n",
    "    cntrl_df.columns = col_names[0:num_cols]\n",
    "    \n",
    "    # Add column validation for counts_df\n",
    "    fdf = cntrl_df.merge(counts_df, how='left', on='barcode').fillna(0)\n",
    "    \n",
    "    if num_cols == 3:\n",
    "        if any(cntrl_df.genotype.isin(['wt', 'WT', 'wildtype'])):\n",
    "            wt_df = fdf[fdf.genotype.isin(['wt', 'WT', 'wildtype'])]\n",
    "        else:\n",
    "            wt_df = pd.DataFrame()\n",
    "    \n",
    "    return wt_df, fdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:47:15.144653Z",
     "start_time": "2022-04-28T18:47:15.136958Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_correlation(control_df: pd.DataFrame, sampleIDs: List, cutoff: float=0.8):\n",
    "    \"\"\"\n",
    "    Given a data frame with a 'concentration' column and sampleID (normalised) counts + list of sampleIDs, \n",
    "    calculate correlation between concentration \n",
    "    return a list of 'good samples', i.e. passing the cutoff\n",
    "    \n",
    "    Assert concentration column is present\n",
    "    Assert sampleIDs are in control_df columns\n",
    "    \"\"\"\n",
    "    concentrations = np.log2(control_df.concentration)\n",
    "    samples = control_df[sampleIDs]\n",
    "    corr_df = pd.DataFrame(samples.corrwith(concentrations), columns=['R'])\n",
    "    corr_df[\"R2\"] = corr_df.R**2\n",
    "    good_samples = corr_df[corr_df.R2 > cutoff].index\n",
    "    return corr_df, good_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:52:18.491458Z",
     "start_time": "2022-04-28T18:52:18.486853Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_correlation_plots(control_df, sampleIDs):\n",
    "    \"\"\"\n",
    "    given a complete control_df, draw correlation plot for each sampleID for each genotype\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:47:27.306637Z",
     "start_time": "2022-04-28T18:47:27.301824Z"
    }
   },
   "outputs": [],
   "source": [
    "not_found_in_dnaid1315 = ['AACAACACGGTAAGCAA', 'AGAATGACCCGGAGGCT', 'AGTCATCGATGCTATAT', 'CCGACGACTGATTGTCC',\n",
    "           'CTACGACAGGGACTTAA', 'GTGTATAGCAGGAACCC', 'GTGTATAGCAGGAACCC', 'TAAGTCCGGGCTAAGTC',\n",
    "           'TATAACACCCCCGATTC', 'TCTCACGCAGCGTTTCG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:47:29.475838Z",
     "start_time": "2022-04-28T18:47:29.427466Z"
    }
   },
   "outputs": [],
   "source": [
    "control_file = root/\"controls_3col.csv\"\n",
    "wt_df, cdf = get_control_counts(control_file, cpms)\n",
    "\n",
    "wt_df = wt_df[~wt_df.barcode.isin(not_found_in_dnaid1315)]\n",
    "df, gs = calculate_correlation(wt_df, sampleIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:26:20.789781Z",
     "start_time": "2022-04-28T15:26:20.753373Z"
    }
   },
   "outputs": [],
   "source": [
    "# cdf1 = cdf[[1]]\n",
    "# cdf1.to_csv(root/\"controls_1col.csv\", index=False, header=None)\n",
    "# cdf2 = cdf[[1,3]]\n",
    "# cdf2.to_csv(root/\"controls_2col.csv\", index=False,header=None)\n",
    "# cdf3 = cdf[[1,3,2]]\n",
    "# cdf3.to_csv(root/\"controls_3col.csv\", index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MAGeCK batch correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T18:57:01.173938Z",
     "start_time": "2022-04-28T18:57:01.156603Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_sample_data(sample_data_file):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mageck_dataset(clean_df, meta_df, library):\n",
    "    batch_file = outDir/f\"{library}_batch.txt\"\n",
    "    count_file = outDir/f\"{library}_count.txt\"\n",
    "    batch_df = meta_df[meta_df.library == library][['sampleID', 'batch', 'day']].sort_values(['day', 'batch'])\n",
    "    batch_df.to_csv(batch_file, index=False, sep='\\t')\n",
    "    magDf = clean_df[clean_df.library == library]\n",
    "    magDf2 = magDf[['barcode', 'ShortName', 'barcode_cnt', 'sampleID']]\n",
    "    magDf2 = (magDf2.pivot(index=['barcode', 'ShortName'], columns='sampleID', values = 'barcode_cnt')\n",
    "         .reset_index().rename({'ShortName': 'gene'}, axis=1)\n",
    "          .fillna(0))\n",
    "    magDf2.to_csv(count_file, index=False, sep='\\t')\n",
    "    return batch_file, count_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(args):\n",
    "    \"\"\"Run command, transfer stdout/stderr\"\"\"\n",
    "    result = subprocess.run(args)\n",
    "    try:\n",
    "        result.check_returncode()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise e\n",
    "        \n",
    "\n",
    "def batch_correct(outDir, library,  r_path=\"./batchCorrect.R\"):\n",
    "    count_path = outDir / f\"{library}_count.txt\"\n",
    "    batch_path = outDir / f\"{library}_batch.txt\"\n",
    "    cmd = f'Rscript {r_path} {count_path} {batch_path} {library} {outDir}'\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())\n",
    "\n",
    "\n",
    "def get_contrast_samples(library_df, treat_col = 'day', treatment='d1', control='d0', sampleID = 'sampleID'):\n",
    "    controls = \",\".join(library_df[library_df[treat_col] == control][sampleID].unique())\n",
    "    treats = \",\".join(library_df[library_df[treat_col] == treatment][sampleID].unique())\n",
    "    return controls, treats\n",
    "\n",
    "\n",
    "def run_mageck(count_file, treated, controls, out_prefix, control_barcode_file):\n",
    "    cmd = (f\"mageck test -k {count_file} -t {treated} \"\n",
    "          f\"-c {controls}  -n {out_prefix} \"  \n",
    "          f\"--control-sgrna {control_barcode_file}  --normcounts-to-file\")\n",
    "    print(cmd)\n",
    "    r = run_command(cmd.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each library:\n",
    "library='library_12_2'\n",
    "meta = meat[meat.library == library]\n",
    "c = all_contrasts[library]\n",
    "\n",
    "\n",
    "def mageck_library(library, meta, outDir, contrasts, control_barcode_file, batch_corr=True, batch_col='batch'):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. Check if batch correction is needed, run if yes -> different count file as input for mageck\n",
    "    2. For each contrast check if threr are samples, run mageck\n",
    "    3. Concatenate results for multiple days\n",
    "\n",
    "    \"\"\"\n",
    "    print(meta[batch_col].nunique())\n",
    "    if batch_corr is True and meta[batch_col].nunique() > 1:\n",
    "        batch_correct(outDir, library,  r_path=\"./batchCorrect.R\")\n",
    "        count_file = outDir/f\"{library}_count_batchcorrected.txt\"\n",
    "    else:\n",
    "        count_file = outDir/f\"{library}_count.txt\"\n",
    "        \n",
    "    result_dfs = []\n",
    "    for contrast, samples in contrasts.items():\n",
    "        print(contrast)\n",
    "        if len(samples[0]) == 0 or len(samples[1]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            treated = samples[1] \n",
    "            controls = samples[0]\n",
    "        out_prefix = outDir/f\"{library}-{contrast}\"\n",
    "        run_mageck(count_file, treated, controls, out_prefix, control_barcode_file)\n",
    "        res = pd.read_table(f'{out_prefix}.gene_summary.txt').assign(contrast=contrast)\n",
    "        result_dfs.append(res)\n",
    "    results = pd.concat(result_dfs).assign(library=library)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_correct():\n",
    "    \"\"\"\n",
    "    Given count df only with good samples\n",
    "    sample data df (read in and validated somewhere else) with information about batches etc. \n",
    "    batch column name\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
