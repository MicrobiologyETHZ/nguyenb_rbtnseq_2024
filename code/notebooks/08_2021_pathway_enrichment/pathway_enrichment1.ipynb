{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d97ba-ce8b-4f42-a7bc-a72e050dd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ../../../data/27_07_results_and_figures/final_results/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting annotations ... -> not ideal needs to be refactores\n",
    "\n",
    "# Todo: move file directories to config files, so that can be re-run with different counts\n",
    "\n",
    "\n",
    "def load_files(samples, results_dir):\n",
    "    df_list = []\n",
    "    cntrl_list = []\n",
    "    for sample in samples:\n",
    "        df_list.append(pd.read_csv(Path(results_dir)/sample/\"merged_counts.csv\", index_col=0))\n",
    "        cntrl_list.append(pd.read_csv(Path(results_dir)/sample/\"merged_controls.csv\", index_col=0))\n",
    "    return pd.concat([pd.concat(df_list), pd.concat(cntrl_list)])\n",
    "\n",
    "\n",
    "counts_dir =\"/Users/ansintsova/git_repos/nguyenb_tnseq/data/13_04_results/counts\"\n",
    "outdir = '/Users/ansintsova/git_repos/nguyenb_tnseq/data/07_06_results/'\n",
    "control_file = Path(\"/Users/ansintsova/git_repos/nguyenb_tnseq/data/13_04_results\")/'controls.txt'\n",
    "\n",
    "# Load\n",
    "dnaids = ['dnaid1315', 'dnaid1428', 'dnaid1429', 'dnaid1457', 'dnaid2015', 'dnaid2016', 'dnaid2017', 'dnaid2018', 'dnaid2019',\n",
    "         'dnaid2023', 'dnaid2024', 'dnaid2025', 'dnaid2026', 'dnaid2027', 'dnaid2028', 'dnaid2029' ]\n",
    "\n",
    "cnt_df = load_files(dnaids, Path(counts_dir))\n",
    "# Create unique identifier for each sample\n",
    "cnt_df['sampleID'] = cnt_df['sampleID'] + \"_\" + cnt_df['dnaid'] + \"_\" + cnt_df['experiment']\n",
    "cnt_df = cnt_df[cnt_df.sampleID.notnull()]\n",
    "cnt_df['CntrlName'] = cnt_df['phenotype'] + cnt_df['conc'].astype(str)\n",
    "cnt_df['ShortName'] = cnt_df.ShortName.fillna(cnt_df.CntrlName)\n",
    "\n",
    "# Dropping Unenriched samples\n",
    "cnt_df = cnt_df[~cnt_df.sampleID.str.contains('unenriched')]\n",
    "annotation_df = cnt_df[['barcode', 'ShortName', 'locus_tag', 'phenotype', 'conc']].drop_duplicates()\n",
    "\n",
    "libraries = [lib for lib in cnt_df.library.unique() if type(lib) == str]\n",
    "libraries.remove('library_14_1')\n",
    "print(len(libraries))\n",
    "days = ['_d1', '_d2', '_d3', '_d4']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = cnt_df[['ShortName', 'locus_tag']].drop_duplicates()\n",
    "#ann = ann[ann.ShortName]\n",
    "ann = ann[ann.ShortName.apply(lambda x: len(x) < 10)]\n",
    "ann.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking should be done within each day, within each library, then take median rank for each gene\n",
    "df = pd.read_csv(\"../../../data/27_07_results_and_figures/final_results/26-07-final-results.csv\", index_col=0)\n",
    "df['dir_change'] = df['z-score'].apply(lambda x: 1 if x > 0 else -1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201918f-9ff4-4f60-98bd-92edaca5f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in final results table\n",
    "#df = pd.read_csv(\"../../results/26-07-final-results.csv\", index_col=0)\n",
    "#df = pd.read_csv(\"../../../data/27_07_results_and_figures/final_results/26-07-final-results.csv\", index_col=0)\n",
    "# Rank all genes based on direction of change and adjusted p-value\n",
    "\n",
    "df['dir_change'] = df['z-score'].apply(lambda x: 1 if x > 0 else -1)\n",
    "df['rank'] = -1*np.log10(df['zscore_padj'])*df['dir_change']\n",
    "df = df.merge(ann, how='left', left_on = 'gene', right_on ='ShortName').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd2edd-f99f-42df-aed1-bd20fbb491c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10).sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by days\n",
    "df1 = df[df.day == 'd1']\n",
    "# Calculate mean, median, min, max rank for each gene\n",
    "ranked = df1.groupby('locus_tag').agg({'rank':['mean', 'median', 'min', 'max']}).dropna().reset_index()\n",
    "ranked.columns = ['locus_tag', 'rank_mean', 'rank_median','rank_min', 'rank_max']\n",
    "\n",
    "# Test these with fgsea\n",
    "\n",
    "# Mean performed the best\n",
    "ranked_mean = ranked[['locus_tag', 'rank_mean']]\n",
    "ranked_mean.to_csv(\"./day1_ranked_mean.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df2 = df[df.day == 'd2']\n",
    "\n",
    "ranked = df2.groupby('locus_tag').agg({'rank':['mean', 'median', 'min', 'max']}).dropna().reset_index()\n",
    "ranked.columns = ['locus_tag', 'rank_mean', 'rank_median','rank_min', 'rank_max']\n",
    "\n",
    "ranked_mean = ranked[['locus_tag', 'rank_mean']]\n",
    "ranked_mean.to_csv(\"./day2_ranked_mean.csv\")\n",
    "\n",
    "\n",
    "df3 = df[df.day == 'd3']\n",
    "\n",
    "ranked = df3.groupby('locus_tag').agg({'rank':['mean', 'median', 'min', 'max']}).dropna().reset_index()\n",
    "ranked.columns = ['locus_tag', 'rank_mean', 'rank_median','rank_min', 'rank_max']\n",
    "\n",
    "ranked_mean = ranked[['locus_tag', 'rank_mean']]\n",
    "ranked_mean.to_csv(\"./day3_ranked_mean.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df4 = df[df.day == 'd4']\n",
    "\n",
    "ranked = df4.groupby('locus_tag').agg({'rank':['mean', 'median', 'min', 'max']}).dropna().reset_index()\n",
    "ranked.columns = ['locus_tag', 'rank_mean', 'rank_median','rank_min', 'rank_max']\n",
    "\n",
    "ranked_mean = ranked[['locus_tag', 'rank_mean']]\n",
    "ranked_mean.to_csv(\"./day4_ranked_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For STRING get all the hits by day\n",
    "# Day 1\n",
    "print(\"\\n\".join(list(df[(df.zscore_padj < 0.05) & (df.day == 'd1')].gene.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ee83f-36fb-41bf-b765-270a96eb1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l102d1[['gene', 'z-score']].to_csv('../../results/25-08-l102d1-gene-zscore.csv', index=None)\n",
    "# No enrichment detected\n",
    "l102d1[['gene', 'log2FC']].to_csv('../../results/25-08-l102d1-gene-log2fc.csv', index=None)\n",
    "# Nothing\n",
    "#Try day 2\n",
    "l102d2[['gene', 'z-score']].to_csv('../../results/25-08-l102d2-gene-zscore.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432402e6-69e9-4220-b9a7-7f24ea527768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only hits\n",
    "l102d1[l102d1.zscore_padj < 0.05][['gene']].to_csv('../../results/25-08-l102d1-gene-hits.csv', index=None, header=None)\n",
    "# all hits\n",
    "pd.Series(df1[df1.zscore_padj < 0.05].gene.unique()).to_csv('../../results/25-08-d1-gene-hits.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ef175-1e9a-4582-a3cb-8b39ce0bdd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = [g for g in df.gene if len(g) < 10]\n",
    "# day 1\n",
    "df1 = df[df.day == 'd1']\n",
    "#Explore consitency in the resutls\n",
    "#df1_exp = df1[df1.gene.isin(genes)].groupby(['gene']).agg({'z-score':['mean', 'std', 'median'], 'log2FC':['mean', 'std', 'median']}).dropna()\n",
    "#df1_exp.columns = ['zscore_mean', 'zscore_std', 'zscore_median', 'fc_mean', 'fc_std', 'fc_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f7bf7-d6cf-4bb0-9576-8bcc04a79ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df1_exp, x=\"zscore_mean\", y=\"normstd\", log_y=True, hover_data=[df1_exp.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = df1.groupby('locus_tag').agg({'rank':['mean', 'median', 'min', 'max', 'std']}).dropna().reset_index()\n",
    "ranked.columns = ['locus_tag', 'rank_mean', 'rank_median','rank_min', 'rank_max', 'rank_std'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked.sort_values('rank_mean').head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with mean\n",
    "ranked_mean = ranked[['locus_tag', 'rank_mean']]\n",
    "ranked_mean.to_csv(\"./ranked_mean.csv\")\n",
    "\n",
    "ranked_median = ranked[['locus_tag', 'rank_median']]\n",
    "ranked_median.to_csv(\"./ranked_median.csv\")\n",
    "\n",
    "\n",
    "ranked_median = ranked[['locus_tag', 'rank_min']]\n",
    "ranked_median.to_csv(\"./ranked_min.csv\")\n",
    "# Try with median\n",
    "\n",
    "# Try with max absolute rank for each gene\n",
    "\n",
    "\n",
    "# MEAN MAKES MOST SENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.gene == 'bapA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-highland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
