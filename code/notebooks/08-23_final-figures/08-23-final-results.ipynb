{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Test\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../snippets/basic_settings.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import yaml\n",
    "import pyranges as pr \n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 12)\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as fh:\n",
    "    config_dict = yaml.safe_load(fh)\n",
    "\n",
    "out_dir = Path(config_dict['out_dir'])\n",
    "map_dir = Path(config_dict['map_dir'])\n",
    "analysis_dir = Path(config_dict['analysis_dir'])\n",
    "gff_file = config_dict['gff_file']\n",
    "gff = pr.read_gff3(gff_file)\n",
    "counts_dir = Path(config_dict['counts_dir'])\n",
    "sd = pd.read_csv(config_dict['sample_data_file'])\n",
    "\n",
    "alphabetClrs = px.colors.qualitative.Alphabet\n",
    "\n",
    "\n",
    "sushi_colors = {'red': '#C0504D',\n",
    "             'orange': '#F79646',\n",
    "             'medSea': '#4BACC6', \n",
    "             'black': '#000000',\n",
    "             'dgreen': '#00B04E',\n",
    "             'lgreen': '#92D050',\n",
    "             'dblue': '#366092',\n",
    "             'lblue': '#95B3D7',\n",
    "             'grey': alphabetClrs[8]}\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_used = ['library_9_1', 'library_12_1', 'library_10_1', 'library_11_2',\n",
    "       'library_10_2', 'library_15_1', 'library_14_2', 'library_13_1',\n",
    "       'library_13_2', 'library_12_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd['name'] = sd['mouse'] + \"_\" + sd['library'] + \"_\" + sd['day'] + \"_\"+ sd['dnaid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = sd.rename(columns={'sampleID':'sample_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = list(map_dir.rglob(\"*/*annotated.csv\"))\n",
    "map_df = pd.concat([pd.read_csv(f).assign(library=f.stem.split(\".annotated\")[0]) for f in maps])\n",
    "map_sum = map_df.groupby('library').agg({'barcode':['nunique'], 'ID':['nunique']}).reset_index()\n",
    "map_sum.columns = ['library', 'num_inserts', 'num_genes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = map_df[map_df.library.isin(libraries_used)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df['Library'] = map_df['library'].str.replace(\"library_\", '').str.replace('_', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(map_df[map_df.chr == 'FQ312003.1'].sort_values('Library'), x='insertion_site', color='Library', nbins=100, \n",
    "             template='plotly_white', width=1000, height=700, color_discrete_sequence=px.colors.sequential.gray, \n",
    "             labels={'insertion_site': 'Position, bp'}, log_y=False)\n",
    "\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black',\n",
    "                tickfont=dict(size=24, color='black'),  titlefont=dict(size=24, color='black'))\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', title='Number of insertions',\n",
    "                tickfont=dict(size=20, color='black'), titlefont=dict(size=30, color='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_gene_summary = map_df.groupby('Name').library.nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(map_gene_summary, x='library', \n",
    "             template='plotly_white', width=900, height=700, color_discrete_sequence=px.colors.sequential.gray, \n",
    "             labels={'insertion_site': 'Position, bp'}, log_y=False)\n",
    "\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', title='Libraries containing the gene disruption', tickvals = [1,2,3,4,5,6,7,8,9,10],\n",
    "                tickfont=dict(size=20, color='black'),  titlefont=dict(size=24, color='black'))\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', title='Number of genes',\n",
    "                tickfont=dict(size=24, color='black'), titlefont=dict(size=30, color='black'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "import pyranges as pr\n",
    "gen_len = 4878012\n",
    "\n",
    "def simulate_insertions(genome_length, cds, depth=[1000], iterations=1, seed=42):\n",
    "    res = None\n",
    "    if iterations > 100000:\n",
    "        print('Max number of iterations allowed is 100000')\n",
    "        return None\n",
    "    seeds = np.random.choice(100000, size=iterations)if iterations > 1 else [seed]\n",
    "    df_list = []\n",
    "    for seed in seeds:\n",
    "        grs = {}\n",
    "        for d in depth:\n",
    "            prng = RandomState(seed)\n",
    "            p = [1/genome_length]*genome_length\n",
    "            starts = np.unique(prng.choice(genome_length, size=d, p=p))\n",
    "            ends = starts+1\n",
    "            chromosome = \"FQ312003.1\"\n",
    "            grs[f'{d}']= pr.from_dict({'Chromosome':[chromosome]*len(starts), 'Start':starts, 'End':ends})\n",
    "        ovs = pr.count_overlaps(grs, cds).as_df()\n",
    "        df_list.append(pd.DataFrame((ovs[list(grs.keys())] > 0).sum()).T)\n",
    "    \n",
    "    return pd.concat(df_list).melt(var_name='num_inserts', value_name='num_genes')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_len = 4878012\n",
    "cds = gff[gff.Feature == 'CDS']\n",
    "simulated = simulate_insertions(gen_len, cds, [1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000], 5)\n",
    "simulated['num_inserts'] = simulated['num_inserts'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(simulated, x='num_inserts', y='num_genes', template='plotly_white',  log_x=True, width=900, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(simulated, x='num_inserts', y='num_genes', template='plotly_white',  log_x=True, width=900, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = map_df.barcode.nunique()\n",
    "Y_all = map_df.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_used = map_df[map_df.library.isin(libraries_used)].barcode.nunique()\n",
    "Y_used = map_df[map_df.library.isin(libraries_used)].ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sum.to_csv(out_dir/'map_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=simulated.num_inserts, y=simulated.num_genes,\n",
    "    name='Simulated Libraries',\n",
    "    mode='markers',\n",
    "    marker = dict(color='grey', opacity=0.3, size=8, line=dict(color='black', width=1))\n",
    "    \n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[X_all], y=[Y_all],\n",
    "    name='Full library collection',\n",
    "    marker= dict(color='red', size=14, symbol= 'cross', line=dict(color='black', width=1))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[X_used], y=[Y_used],\n",
    "    name='Libraries Used',\n",
    "    marker= dict(color='blue', size=14, symbol= 'x', line=dict(color='black', width=1))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=map_sum.num_inserts, y=map_sum.num_genes,\n",
    "    name='Libraries Used',\n",
    "    mode='markers',\n",
    "    marker= dict(color='green', size=10, symbol= 'star', line=dict(color='black', width=1))\n",
    "))\n",
    "\n",
    "# Set options common to all traces with fig.update_traces\n",
    "\n",
    "fig.update_layout(title='Styled Scatter', template='plotly_white',\n",
    "                  yaxis_zeroline=False, xaxis_zeroline=False, width=800, height=600)\n",
    "fig.update_xaxes(type='log', title='Total number of unique inserts/barcodes')\n",
    "fig.update_yaxes( title='Total number of CDS disrupted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfiles = list(counts_dir.rglob(\"*mbarq_merged_counts.csv\"))\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cfiles[0]).drop(['barcode'], axis=1)\n",
    "\n",
    "df2 = pd.read_csv(cfiles[1]).drop(['barcode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.melt(id_vars=['Name'], var_name='sample_id', value_name='cnt').groupby(['sample_id', 'Name']).cnt.sum().reset_index()\n",
    "df2 = df2.melt(id_vars=['Name'], var_name='sample_id', value_name='cnt').groupby(['sample_id', 'Name']).cnt.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tts'] = np.log2(df['cnt']/df.groupby('sample_id')['cnt'].transform('sum')*1000000 +0.5)\n",
    "df2['tts'] = np.log2(df2['cnt']/df.groupby('sample_id')['cnt'].transform('sum')*1000000 +0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.tts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.merge(sd[['sample_id', 'name']], on='sample_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.pivot(index='Name', columns='name', values='tts').fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list(analysis_dir.glob(\"*rra_results.csv\"))\n",
    "df_list = []\n",
    "for f in result_files:\n",
    "    df = pd.read_csv(f).assign(library=f.stem.split(\"_rra\")[0])\n",
    "    df_list.append(df)\n",
    "fdf = pd.concat(df_list)\n",
    "fdf['hit'] = (abs(fdf.LFC) > 1) &((fdf.neg_selection_fdr < 0.05) | (fdf.pos_selection_fdr < 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_used = fdf.library.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1\n",
    "table1 = fdf.groupby(['library', 'contrast']).agg({'locus_tag':['nunique'], 'hit':['sum'],\n",
    "                                          'LFC': ['median']}).reset_index()\n",
    "table1.columns = ['library', 'day', 'number_genes_analysed', 'number_hits', 'median_LFC']\n",
    "table1                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsig = fdf.query(\"(abs(LFC) > 1) &(neg_selection_fdr < 0.05 | pos_selection_fdr < 0.05)\")\n",
    "rsig.groupby(['library', 'contrast']).locus_tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlations\n",
    "cor_df = (fdf[['locus_tag', 'contrast', 'LFC', 'library']]\n",
    "          .pivot(index=['locus_tag', 'contrast'], columns='library')\n",
    "          .reset_index()\n",
    "          .set_index('locus_tag')\n",
    "          .groupby('contrast')\n",
    "          .corr()\n",
    "          .reset_index())\n",
    "df_list = []\n",
    "for i, g in cor_df.groupby('contrast'):\n",
    "    df = g.drop(['level_1'], axis=1).set_index(['contrast', 'library'])\n",
    "    df = (df.mask(np.triu(np.ones(df.shape, dtype=np.bool_)))\n",
    "          .stack()\n",
    "          .rename_axis(('contrast', 'lib1', 'lib2'))\n",
    "          .reset_index()\n",
    "          .rename(columns={'LFC': 'R'}))\n",
    "    df_list.append(df)\n",
    "cor_df = pd.concat(df_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size=24\n",
    "fig = px.box(cor_df, x='contrast', y='R', color_discrete_sequence = ['black']*4, \n",
    "                  labels={\"contrast\":'', 'R': \"Pearson's <i>r</i>\"},\n",
    "                  height=500, width=400,  template='plotly_white')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black',\n",
    "                         tickfont=dict(size=font_size-6, color='black'), \n",
    "                 titlefont=dict(size=font_size, color='black'))\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', range=[0, 1],\n",
    "                        tickfont=dict(size=font_size-6, color='black'), \n",
    "                 titlefont=dict(size=font_size, color='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = (fdf.query('(library==\"library_10_2\" | library == \"library_11_2\") ')[['locus_tag', 'LFC', 'library', 'contrast']]\n",
    "        .pivot(index=['locus_tag', 'contrast'], columns='library')\n",
    "        .dropna()\n",
    "        .reset_index())\n",
    "ex_df.columns = ['locus_tag','contrast', 'library_10_1', 'library_12_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(ex_df, x='library_10_1', y='library_12_1',color='contrast', width=500, height=500, \n",
    "            template='plotly_white', trendline='ols' )\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(ex_df, x='library_10_1', y='library_12_1', color='contrast', \n",
    "                     height=600, width=800,\n",
    "                     template = 'plotly_white', \n",
    "                     labels = {'library_10_1': 'LFC(library 10-1)', \n",
    "                               'library_12_1': 'LFC (library 12-1)'},\n",
    "                     color_discrete_map = {'d1': sushi_colors['red'], \n",
    "                                           'd2': sushi_colors['dgreen'], \n",
    "                                           'd3': sushi_colors['dblue'], \n",
    "                                           'd4': sushi_colors['orange']},\n",
    "                #hover_data=['locus_tag', 'gene'],\n",
    "                category_orders = {'contrast':['d1', 'd2', 'd3','d4']}, trendline='ols')\n",
    "\n",
    "fig.update_traces(marker=dict(size=14, line=dict(width=1, color='DarkSlateGrey'), \n",
    "                                opacity=0.9),\n",
    "                    selector=dict(mode='markers'))\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black',\n",
    "                        tickfont=dict(size=font_size-6, color='black'), \n",
    "                    titlefont=dict(size=font_size, color='black'), range=[-14,8])\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black',\n",
    "                    tickfont=dict(size=font_size-6, color='black'), \n",
    "                    titlefont=dict(size=font_size, color='black'), range=[-14,8])\n",
    "\n",
    "fig.update_layout(legend=dict(font=dict(size=font_size-2)), \n",
    "                    legend_title=dict(font=dict(size=font_size)))\n",
    "\n",
    "tr_line=[]\n",
    "for  k, trace  in enumerate(fig.data):\n",
    "        if trace.mode is not None and trace.mode == 'lines':\n",
    "            tr_line.append(k)\n",
    "print(tr_line)\n",
    "\n",
    "for id in tr_line:\n",
    "    fig.data[id].update(line_width=6)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dir = Path('/nfs/cds-peta/exports/biol_micro_cds_gr_sunagawa/scratch/ansintsova/Projects_NCCR/hardt/nguyenb/tnseq/scratch/manuscript_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = pd.read_csv(gt_dir/\"nguyen_2020/nguyen_2020_inframe_mut_phenotypes.csv\")\n",
    "phenotypes[phenotypes['day'] == 'd4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, balanced_accuracy_score\n",
    "\n",
    "phenotypes = pd.read_csv(gt_dir/\"nguyen_2020/nguyen_2020_inframe_mut_phenotypes.csv\")\n",
    "phenotypes = phenotypes.rename({'day': 'contrast'}, axis=1)\n",
    "phenotypes = phenotypes.merge(fdf, how='left', left_on=['gene', 'contrast'], right_on=['locus_tag', 'contrast'])\n",
    "\n",
    "\n",
    "# Same definition of hit as before\n",
    "phenotypes['pheno_hit'] = ((phenotypes['adjusted p value (C.I.)'] <0.05) & (abs(np.log2(phenotypes['median'])) > 0.6)).astype(int)\n",
    "phenotypes = phenotypes[['locus_tag', 'gene', 'adjusted p value (C.I.)', 'median', 'contrast', 'pheno_hit', 'hit', 'library']]\n",
    "phenotypes = phenotypes.dropna()\n",
    "phenotypes['mbarq_hit'] = phenotypes.hit.astype(int)\n",
    "\n",
    "metrics = {'mBARq Analysis': (precision_score(phenotypes.pheno_hit, phenotypes.mbarq_hit), \n",
    "                     recall_score(phenotypes.pheno_hit, phenotypes.mbarq_hit), \n",
    "                     balanced_accuracy_score(phenotypes.pheno_hit, phenotypes.mbarq_hit)), }\n",
    "\n",
    "\n",
    "metric_df = (pd.DataFrame(metrics, index=['Precision', 'Recall', 'Balanced Accuracy'])\n",
    "              .T\n",
    "            .reset_index()\n",
    "            .rename({'index':'Method'}, axis=1)\n",
    "              .melt(id_vars=['Method'], var_name='Metric', value_name='Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.groupby(['library', 'contrast']).agg({'gene': ['nunique'], 'pheno_hit': ['sum']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = phenotypes.groupby(['library', 'contrast']).apply(lambda x: pd.Series({'Precision':  precision_score(x.pheno_hit, x.mbarq_hit),\n",
    "                                                            'Recall': recall_score(x.pheno_hit, x.mbarq_hit)})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric.melt(id_vars=['library', 'contrast'], var_name='metric', value_name='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(metric, x='contrast', y='score', color='metric', color_discrete_sequence = [sushi_colors['dblue'], sushi_colors['lblue']],\n",
    "                        template='plotly_white', height=400, width=600)\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black',\n",
    "                         tickfont=dict(size=font_size-6, color='black'), \n",
    "                 titlefont=dict(size=font_size, color='black'))\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', range=[0, 1.15],\n",
    "                        tickfont=dict(size=font_size-6, color='black'), \n",
    "                 titlefont=dict(size=font_size, color='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fdf.to_csv(out_dir/'final-results-all-libraries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rsig.to_csv(out_dir/'final-results-all-libraries-significant-only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sum = rsig.groupby(['library', 'contrast']).agg({'locus_tag':['nunique']}).reset_index()\n",
    "res_sum.columns = ['library', 'contrast', 'number_of_hits']       \n",
    "#res_sum.to_csv(out_dir/'number_of_hits_per_library.csv', index=False)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rsig.groupby(['contrast', 'locus_tag'])\n",
    "                          .library.nunique()\n",
    "                          .reset_index()\n",
    "                          .rename(columns={'library': 'num_hit'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf['padj'] = fdf[['neg_selection_fdr','pos_selection_fdr']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hit = (fdf.groupby(['contrast', 'locus_tag'])\n",
    "           .agg({'library':['nunique'], 'LFC':['median'], 'padj':['min', 'max']})\n",
    "           .reset_index())\n",
    "num_hit.columns = ['contrast', 'locus_tag', 'num_lib', 'LFC_median', 'padj_min', 'padj_max']\n",
    "num_hit =  (num_hit.merge(rsig.groupby(['contrast', 'locus_tag'])\n",
    "                          .library.nunique()\n",
    "                          .reset_index()\n",
    "                          .rename(columns={'library': 'num_hit'}), \n",
    "            on=['contrast', 'locus_tag'], how='outer'))\n",
    "num_hit['num_hit'] = num_hit['num_hit'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[fdf.locus_tag == 'RygC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hit[num_hit.locus_tag == 'RygC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hit.columns = ['day', 'locus_tag', 'number_of_libraries_with_mutant', 'LFC_median', 'padj_min', 'padj_max', 'number_of_times_detected_as_hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hit = num_hit[['locus_tag', 'day', 'LFC_median', 'number_of_libraries_with_mutant', 'number_of_times_detected_as_hit', 'padj_min', 'padj_max']].sort_values(['day','LFC_median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = num_hit.pivot(index=['locus_tag', 'number_of_libraries_with_mutant'], columns='day', \n",
    "              values=['LFC_median', 'number_of_times_detected_as_hit', 'padj_min', 'padj_max']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [f'{col_name}_{day}' for col_name in ['LFC_median', 'number_of_times_detected_as_hit', \n",
    "                                                  'padj_min', 'padj_max'] for day in ['d1', 'd2', 'd3', 'd4']]\n",
    "final_summary.columns = ['locus_tag', 'number_of_libraries_with_mutant'] + col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary.to_csv(out_dir/'12-09-final-results-gene-level-summary.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "def string_function(gene_names, species):\n",
    "    string_api_url = \"https://version-11-5.string-db.org/api\"\n",
    "    output_format = \"json\"\n",
    "    method = \"enrichment\"\n",
    "\n",
    "\n",
    "    ##\n",
    "    ## Construct the request\n",
    "    ##\n",
    "\n",
    "    request_url = \"/\".join([string_api_url, output_format, method])\n",
    "\n",
    "    ##\n",
    "    ## Set parameters\n",
    "    ##\n",
    "    params = {\n",
    "\n",
    "        \"identifiers\" : \"\\r\".join(gene_names),  # your protein\n",
    "        \"species\" : species, # species NCBI identifier \n",
    "        \"caller_identity\" : \"test_api\" # your app name\n",
    "\n",
    "    }\n",
    "\n",
    "    response = requests.post(request_url, data=params)\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def get_functional_analysis(df, day, direction, out_dir):\n",
    "    d = '< -1' if direction == 'decreased-fitness' else '> 1'\n",
    "    genes = df.query(f\"LFC_median {d} & day == '{day}'\").locus_tag.values\n",
    "    data = pd.DataFrame(string_function(genes, 99287))\n",
    "    data.to_csv(out_dir/f\"{day}_{direction}_functional-analysis.csv\", index=False)\n",
    "    return data\n",
    "\n",
    "# Day 1 down\n",
    "day = 'd1'\n",
    "direction = 'decreased-fitness'\n",
    "r = get_functional_analysis(num_hit, day, direction, out_dir)\n",
    "\n",
    "# Day 1 up\n",
    "day = 'd1'\n",
    "direction = 'increased-fitness'\n",
    "get_functional_analysis(num_hit, day, direction, out_dir)\n",
    "\n",
    "# Day 2 down\n",
    "day = 'd2'\n",
    "direction = 'decreased-fitness'\n",
    "get_functional_analysis(num_hit, day, direction, out_dir)\n",
    "\n",
    "# Day 2 up\n",
    "day = 'd2'\n",
    "direction = 'increased-fitness'\n",
    "get_functional_analysis(num_hit, day, direction, out_dir)\n",
    "\n",
    "# Day 3 down\n",
    "day = 'd3'\n",
    "direction = 'decreased-fitness'\n",
    "get_functional_analysis(num_hit, day, direction, out_dir)\n",
    "\n",
    "# Day 3 up\n",
    "day = 'd3'\n",
    "direction = 'increased-fitness'\n",
    "get_functional_analysis(num_hit, day, direction, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 'd1'\n",
    "direction = 'decreased-fitness'\n",
    "r = get_functional_analysis(num_hit, day, direction, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [()'Lipopolysaccharide biosynthesis', 'KW-0448'), ('O-Antigen nucleotide sugar biosynthesis', 'CL:4794'), ('RNA degradation', ), ('AA biosynthetic process and ..', 'CL:1292')]\n",
    "\n",
    "# General to use: Carbohydrate metabolic process , Lipid metabolic process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.sort_values('number_of_genes', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r[['term', 'inputGenes', 'description']]\n",
    "r.explode('inputGenes').sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.KEGG import REST\n",
    "from Bio.KEGG import Gene\n",
    "# Standard library packages\n",
    "import io\n",
    "import os\n",
    "\n",
    "# A bit of code that will help us display the PDF output\n",
    "def PDF(filename):\n",
    "    return HTML('<iframe src=%s width=700 height=350></iframe>' % filename)\n",
    "\n",
    "# Some code to return a Pandas dataframe, given tabular text\n",
    "def to_df(result):\n",
    "    return pd.read_table(io.StringIO(result), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ko03110.keg') as handle:\n",
    "    for record in Gene.parse(handle):\n",
    "        print(record.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = REST.kegg_list(\"pathway\", 'sey').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sey_pathways = to_df(result)\n",
    "sey_pathways.columns = ['path_id', 'path_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sey_pathways[sey_pathways.path_desc.str.contains(\"Lipo\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = ['sey00010', 'sey00020', 'sey00030', 'sey00190', 'sey01230', 'sey00230', 'sey00240',  'sey00061', 'sey00071', 'sey01240',\n",
    "            'sey02010', 'sey02020', \"sey00540\", \"sey00541\", \"sey02010\", \"sey01212\", \"sey01200\"]\n",
    "\n",
    "brite = ['sey02000', 'sey01005', 'sey03110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html,etree\n",
    "\n",
    "def get_genes_for_pathway_v2(pathway=\"sey01212\", db='path'):\n",
    "    url = f\"https://www.genome.jp/dbget-bin/get_linkdb?-t+genes+{db}:{pathway}\"\n",
    "    try:\n",
    "        page = requests.get(url).content.decode('utf-8')\n",
    "        tree = etree.parse(io.StringIO(page), parser=etree.HTMLParser())\n",
    "        refs = tree.xpath(\"//a\")\n",
    "        links = [link.get('href', '') for link in refs]\n",
    "        links = [l for l in links if 'sey:SL1344' in l]\n",
    "        return [l.split(\"sey:\")[1] for l  in links]\n",
    "    except HTTPError:\n",
    "        print(\"Bad pathway name\")\n",
    "\n",
    "def get_gene_info(locus_tags):\n",
    "    #slow\n",
    "    gene_ids = []\n",
    "    pattern = r\".*SYMBOL *(\\w*).*ORTHOLOGY *(K[0-9]*)\"\n",
    "    for locus_tag in locus_tags:\n",
    "        desc = REST.kegg_get(f\"sey:{locus_tag}\").read()\n",
    "        matches = re.search(pattern, desc.replace(\"\\n\", ' '))\n",
    "        if matches:\n",
    "            gene_ids.append([locus_tag, matches.group(1), matches.group(2)])\n",
    "    return pd.DataFrame(gene_ids, columns = ['locus_tag', 'Name', 'KO'])\n",
    "\n",
    "\n",
    "def get_kegg_info(pathways, db, gff):\n",
    "    df_list = []\n",
    "    for pathway in pathways:\n",
    "        genes = get_genes_for_pathway_v2(pathway,db)\n",
    "        df_list.append(pd.DataFrame(genes, columns=['locus_tag']).assign(KEGG_Pathway=pathway))\n",
    "    fdf = pd.concat(df_list)\n",
    "    gff = gff[gff.Feature == 'gene'][['Name', 'locus_tag']]\n",
    "    fdf = fdf.merge(gff, how='left', on='locus_tag')\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genes_for_pathway(pathway, ):\n",
    "    try:\n",
    "        lines = REST.kegg_get(pathway).read().split(\"\\n\")\n",
    "        ids = []\n",
    "        pattern = r\"[\\w ]*(SL1344_[0-9]*) .([\\w -]*)(;|\\[)[\\w -\\[]*KO:(K[0-9]*)\"\n",
    "        for line in lines:\n",
    "            matches = re.search(pattern, line)\n",
    "            if matches:\n",
    "                ids.append([matches.group(1), matches.group(2), matches.group(4)])\n",
    "        return pd.DataFrame(ids, columns=['locus_tag', 'Name', 'KO']).assign(KEGG_Pathway=pathway)\n",
    "    except HTTPError:\n",
    "        print(\"Bad pathway name\")\n",
    "\n",
    "df_list = []\n",
    "for pathway in pathways:\n",
    "    df_list.append(get_genes_for_pathway(pathway))\n",
    "ko_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff= pr.read_gff3(Path(config_dict['gff_file'])).as_df()\n",
    "ko_df = get_kegg_info(pathways,db='path', gff=gff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_df2 = get_kegg_info(brite,db='br', gff=gff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_df = pd.concat([ko_df, ko_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_df['gene_id'] = ko_df.Name.apply(lambda x: x if len(x.split()) == 1 else np.nan)\n",
    "ko_df['gene_id'] = ko_df['gene_id'].fillna(ko_df.locus_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = num_hit[num_hit.LFC_median < 0].rename(columns={'locus_tag':'gene_id'}).merge(ko_df, on='gene_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['KEGG_Pathway'] = test[\"KEGG_Pathway\"].fillna('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_df.groupby('KEGG_Pathway').locus_tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.number_of_times_detected_as_hit > 1].groupby('day').gene_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_conf = test[(test.LFC_median < - 1) &(test.number_of_times_detected_as_hit > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = hi_conf.groupby(['day', 'KEGG_Pathway']).gene_id.nunique().reset_index().sort_values('gene_id')\n",
    "test2 = test2[(test2.gene_id >=4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(test2.sort_values('day'), x='day', y='gene_id', color='KEGG_Pathway', height=800, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(REST.kegg_get(\"sey:recR\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.keg', 'w') as fh:\n",
    "    fh.write(REST.kegg_get(\"sey:recO\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.keg\") as handle:\n",
    "    for record in Gene.parse(handle):\n",
    "        print(\"%s %s\" % (record.entry, record.dblinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_conf[(hi_conf.day == 'd4') & (hi_conf.KEGG_Pathway == 'Other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datavis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
