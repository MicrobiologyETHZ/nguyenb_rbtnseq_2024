{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tnseq2.src.analysis import *\n",
    "from pathlib import Path\n",
    "import plotnine as p9\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ranksums\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio\n",
    "import chart_studio.tools as tls\n",
    "import chart_studio.plotly as py\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import cufflinks as cf\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import dash_bio as dashbio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/ansintsova/git_repos/nguyenb_tnseq/data/13_04_results\"\n",
    "counts = 'counts'\n",
    "results = 'results'\n",
    "control_file = Path(root)/'controls.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnaids = ['dnaid1315', 'dnaid1428', 'dnaid1429', 'dnaid2015', 'dnaid2016', 'dnaid2017', 'dnaid2018', 'dnaid2019',\n",
    "         'dnaid2023', 'dnaid2024', 'dnaid2025', 'dnaid2026', 'dnaid2027', 'dnaid2028', 'dnaid2029' ]\n",
    "\n",
    "def load_merged_results(results_dir):\n",
    "    df = pd.concat([pd.read_csv(file, index_col=0) for file in results_dir.iterdir() if 'merged_results.csv' in file.name])\n",
    "    return df\n",
    "\n",
    "def load_singltons(results_dir):\n",
    "    singles = ['dnaid1315', 'dnaid1428', 'dnaid1429', 'dnaid2019', 'dnaid2027']\n",
    "    df_list = []\n",
    "    for s in singles:\n",
    "        df = pd.read_csv(Path(results_dir)/f'{s}_final_results.csv').assign(dnaid=s)\n",
    "        df = df.rename({'Unnamed: 0': 'gene'}, axis =1)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    return pd.concat(df_list)\n",
    "    \n",
    "    \n",
    "def get_results(results_dir):\n",
    "    df = load_merged_results(Path(root)/results)\n",
    "    df2 = load_singltons(Path(root)/results)\n",
    "    return pd.concat([df, df2])\n",
    "\n",
    "results_df = get_results(Path(root)/results)\n",
    "cnt_df = load_files(dnaids, Path(root)/counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-dispatch",
   "metadata": {},
   "source": [
    "## Find all experiments that were done with the same library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[['library', 'experiment', 'dnaid']].drop_duplicates().dropna().groupby('library').experiment.apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-quarter",
   "metadata": {},
   "source": [
    "- Libraries library_10_2 and library_14_2 were each used in 3 different experiments. Use that as starting point\n",
    "- Let's also look at overlap between those 2 libraries (at a gene level)\n",
    "    - As shown below, overlap is not huge, working with each individually. Later can look at those 632 genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_10_14 = results_df.copy()\n",
    "overlap_10_14 = overlap_10_14[overlap_10_14.library.isin(['library_10_2', 'library_14_2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = overlap_10_14.groupby('gene').library.nunique()\n",
    "print(f\"Overlap is {grouped[grouped >1].shape[0]} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10=results_df[results_df.library == 'library_10_2'].copy()\n",
    "lib14=results_df[results_df.library == 'library_14_2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Library 10_2 has {lib10.gene.nunique()} genes\")\n",
    "print(f\"Library 14_2 has {lib14.gene.nunique()} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-occupation",
   "metadata": {},
   "source": [
    "## Analysis Plan\n",
    "\n",
    "### PCA: \n",
    "\n",
    "- Let's look only at barcodes present > 1000 in the inoculum\n",
    "\n",
    "    - based raw counts\n",
    "    - mean normalized relative abundances\n",
    "    - based on relative abundances\n",
    "    - based on vst transformed counts\n",
    "    - based on clr transformed counts\n",
    "    - based on log2FC for each barcode\n",
    "    - based on z-score for each gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-feeding",
   "metadata": {},
   "source": [
    "## Raw Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_cnt = cnt_df[cnt_df.library == 'library_10_2'].copy()\n",
    "lib10_cnt = lib10_cnt[['barcode', 'sampleID', 'experiment', 'mouse', 'day', 'tissue', 'dnaid', 'cnt']].drop_duplicates()\n",
    "lib10_cnt['sampleID'] = lib10_cnt['sampleID']+ \"_\" + lib10_cnt['dnaid'] + '_' + lib10_cnt['experiment']\n",
    "lib10_sdata = lib10_cnt[['sampleID', 'mouse', 'day', 'tissue', 'dnaid', 'experiment']].set_index('sampleID').drop_duplicates()\n",
    "lib10_cnt = lib10_cnt.pivot(index='barcode', columns='sampleID', values='cnt')\n",
    "lib10_cnt = lib10_cnt.fillna(0)\n",
    "columns_to_filter = [f for f in lib10_cnt.columns if 'inoculum' in f]\n",
    "lib10_cnt = lib10_cnt[(lib10_cnt[columns_to_filter] >= 1000).all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-diamond",
   "metadata": {},
   "source": [
    "## Scaled Raw Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "lib10_relab = lib10_cnt.copy().apply(lambda x: x/x.sum())\n",
    "lib10_cnt_robust = pd.DataFrame(scaler.fit_transform(lib10_relab.T).T)\n",
    "lib10_cnt_robust.columns = lib10_cnt.columns\n",
    "lib10_cnt_robust.index = lib10_cnt.index\n",
    "lib10_cnt_robust.head()\n",
    "#pDf_robust, pc1_robust, pc2_robust = find_pc1_pc2(lib10_cnt_robust, lib10_sdata)\n",
    "#plotPCA(pDf_robust, pc1_robust, pc2_robust, colorby='experiment', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_cnt_robust_noinoc = lib10_cnt_robust[[c for c in lib10_cnt_robust.columns if 'inoculum' not in c]]\n",
    "#pDf_robust2, pc1_robust2, pc2_robust2 = find_pc1_pc2(lib10_cnt_robust_noinoc, lib10_sdata)\n",
    "#plotPCA(pDf_robust2, pc1_robust2, pc2_robust2, colorby='day', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-librarian",
   "metadata": {},
   "source": [
    "## Proportions\n",
    "\n",
    "- Proportions by themselves are not very informative \n",
    "- With RobustScaler can see separation between inoculum and the rest of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pDf_relab, pc1_relab, pc2_relab = find_pc1_pc2(lib10_relab, lib10_sdata)\n",
    "#plotPCA(pDf_relab, pc1_relab, pc2_relab, colorby='experiment', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-barrier",
   "metadata": {},
   "source": [
    "## CLR Transformed Data\n",
    "- CLR and VST transformed data show very similar results\n",
    "- Potentially identify mice that are outliers and should be removed? \n",
    "- Everything else clusters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skbio.stats.composition import clr\n",
    "lib10_clr = lib10_cnt.apply(lambda x: clr(x+1))\n",
    "\n",
    "#pDf_clr, pc1_clr, pc2_clr = find_pc1_pc2(lib10_clr, lib10_sdata)\n",
    "#plotPCA(pDf_clr, pc1_clr, pc2_clr, colorby='day', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-suicide",
   "metadata": {},
   "source": [
    "## VST Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = lib10_sdata\n",
    "edf = lib10_cnt[list(sdf.index)]\n",
    "sdf.to_csv(Path(root)/results/'lib10_sdf.csv')\n",
    "edf.to_csv(Path(root)/results/'lib10_edf.csv')\n",
    "# Run DESeq2\n",
    "lib10_vst = pd.read_csv(Path(root)/results/'lib10_vsd.csv').rename({'Unnamed: 0':'barcode'}, axis=1).set_index('barcode')\n",
    "#pDf_vst, pc1_vst, pc2_vst = find_pc1_pc2(lib10_vst, lib10_sdata)\n",
    "\n",
    "#plotPCA(pDf_vst, pc1_vst, pc2_vst, colorby='day', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = ['am732', 'am730', 'am484']\n",
    "lib10_clr_nooutliers = lib10_clr[[c for c in lib10_clr.columns if 'am732' not in c and 'am730' not in c and 'am484' not in c]]\n",
    "#pDf_clrNO, pc1_clrNO, pc2_clrNO = find_pc1_pc2(lib10_clr_nooutliers, lib10_sdata)\n",
    "#plotPCA(pDf_clrNO, pc1_clrNO, pc2_clrNO, colorby='day', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lib10_vst.ad926_d2_dnaid2017_TV4592A, np.log2(lib10_cnt.ad926_d2_dnaid2017_TV4592A+1), '.k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_relab.ad926_d1_dnaid2017_TV4592A.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_clr.ad926_d1_dnaid2017_TV4592A.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_vst.ad926_d1_dnaid2017_TV4592A.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pc1_pc2(df, meta):\n",
    "    df = df.T\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(df)\n",
    "    pDf = (pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n",
    "           .set_index(df.index))\n",
    "\n",
    "    pc1_var = round(pca.explained_variance_ratio_[0] * 100, 2)\n",
    "    pc2_var = round(pca.explained_variance_ratio_[1] * 100, 2)\n",
    "    pDf2 = pDf.merge(meta, left_index=True, right_index=True)\n",
    "    return pDf2, pc1_var, pc2_var\n",
    "\n",
    "\n",
    "def plotPCA(pDf, pc1_var, pc2_var, colorby, col, nameby=\"\", el=False):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"notebook\", font_scale=2.2)\n",
    "    group = pDf[colorby].unique()\n",
    "    assert len(group) <= len(col)\n",
    "    fig = plt.figure(figsize=(25, 15))\n",
    "    for g, c in zip(group, col):\n",
    "        df = pDf[pDf[colorby] == g]\n",
    "        x, y = df[[\"PC1\"]].values, df[[\"PC2\"]].values\n",
    "        ax = plt.scatter(x, y, c=c, s=150, label=g)\n",
    "        if el:\n",
    "            pts = np.asarray([[float(a), float(b)] for a, b in zip(x, y)])\n",
    "            plot_point_cov(pts, nstd=2, alpha=0.1, color=c)\n",
    "        if nameby:\n",
    "            labels = df[nameby]\n",
    "            for label, pc1, pc2 in zip(labels, x, y):\n",
    "                plt.annotate(label, xy=(pc1, pc2), xytext=(-5, 7), textcoords=\"offset points\",fontsize=14)\n",
    "        plt.xlabel('Principal Component 1, {} %'.format(pc1_var), )\n",
    "        plt.ylabel('Principal Component 2, {} %'.format(pc2_var), )\n",
    "        #plt.xticks(fontsize=16)\n",
    "        #plt.yticks(fontsize=16)\n",
    "        plt.legend(frameon=True)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_vst.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p9.options.figure_size=(10,15)\n",
    "# g3 =(p9.ggplot(data=fdf,\n",
    "#            mapping=p9.aes(x='PC1', y='PC2', color='strain', ))\n",
    "#     + p9.geom_point(size=3)\n",
    "#      + p9.facet_wrap(\"~genotype\", ncol=2)\n",
    "#     + p9.theme_bw()\n",
    "#     + p9.theme(text=p9.element_text(size=14))\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-trance",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_array = ward(lib10_clr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lib10_clr.T\n",
    "rows = list(test.index)\n",
    "cols = list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_clr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "?dashbio.Clustergram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_clr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustergram= dashbio.Clustergram(\n",
    "    data=lib10_clr.corr().values,\n",
    "    return_computed_traces=True,\n",
    "    row_labels=list(lib10_clr.corr().index),\n",
    "    column_labels=list(lib10_clr.corr().columns),\n",
    "#     color_threshold={\n",
    "#         'row': 250,\n",
    "#         'col': 700\n",
    "#     },\n",
    "    #link_fun = scipy.cluster.hierarchy.ward, \n",
    "    height=1000,\n",
    "    width=1200,\n",
    "    hidden_labels='column',\n",
    "    standardize ='none',\n",
    "    generate_curves_dict=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.mouse.unique(), sns.color_palette(\"hls\", 19)))\n",
    "row_colors = lib10_sdata.mouse.map(lut)\n",
    "\n",
    "sns.clustermap(np.log2(lib10_cnt +1).T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors, dendrogram_ratio=(0.5,0.2), cmap =\"vlag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.mouse.unique(), sns.color_palette(\"hls\", 19)))\n",
    "row_colors = lib10_sdata.mouse.map(lut)\n",
    "\n",
    "sns.clustermap(lib10_vst.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors, dendrogram_ratio=(0.5,0.2), cmap =\"vlag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.experiment.unique(), sns.color_palette(\"hls\", 3)))\n",
    "row_colors = lib10_sdata.experiment.map(lut)\n",
    "\n",
    "sns.clustermap(lib10_clr.T, method='average', metric='correlation', \n",
    "               figsize=(20, 20), row_colors=row_colors, dendrogram_ratio=(0.5,0.2), cmap='vlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.day.unique(), sns.color_palette(\"hls\", 5)))\n",
    "row_colors = lib10_sdata.day.map(lut)\n",
    "\n",
    "sns.clustermap(lib10_clr.T, method='average', metric='correlation', figsize=(20, 20), row_colors=row_colors, \n",
    "               cmap='vlag', dendrogram_ratio=(0.5,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(font_scale=.8)\n",
    "# lut = dict(zip(lib10_sdata.day.unique(), sns.color_palette(\"hls\", 5)))\n",
    "# row_colors = lib10_sdata.day.map(lut)\n",
    "\n",
    "# sns.clustermap(lib10_clr.T, method='ward', figsize=(20, 20), row_colors=row_colors, dendrogram_ratio=(0.5,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-cargo",
   "metadata": {},
   "source": [
    "- Check if the outlier mice have stronger bottlenecks. Surprising, because from day1 are different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-episode",
   "metadata": {},
   "source": [
    "## Log2FC for each barcode\n",
    "\n",
    "- Can't get any meaningful signal here\n",
    "- Re-run analysis without shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_res = results_df[results_df.library == 'library_10_2'].copy()\n",
    "lib10_res = lib10_res[['gene', 'experiment', 'dnaid'] + [c for c in lib10_res.columns if 'fitness_mean' in c]].dropna()\n",
    "\n",
    "\n",
    "lib10_res = lib10_res.melt(id_vars=['gene', 'experiment', 'dnaid'], var_name='day', value_name='fitness')\n",
    "lib10_res_samples = lib10_res[abs(lib10_res.fitness) > 1].gene.values\n",
    "lib10_res['day'] = lib10_res['day'].str.split(\"_\", expand=True)[0]\n",
    "weird_cases = lib10_res.groupby(['gene', 'day']).experiment.count().reset_index()\n",
    "weird_cases = weird_cases[weird_cases.experiment > 3].gene.values\n",
    "lib10_res = lib10_res[lib10_res.gene.isin(lib10_res_samples)]\n",
    "lib10_res = lib10_res[~lib10_res.gene.isin(weird_cases)].drop_duplicates()\n",
    "\n",
    "lib10_res['sampleID'] = lib10_res.experiment +\"_\" + lib10_res.dnaid + '_' + lib10_res.day\n",
    "lib10_res = lib10_res.pivot(index='gene', columns='sampleID', values='fitness').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "sns.clustermap(lib10_res.T, method='ward', \n",
    "               figsize=(20, 20), row_colors=row_colors, dendrogram_ratio=(0.5,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-gospel",
   "metadata": {},
   "source": [
    "## Control barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = pd.read_table(control_file, index_col=0, names = ['barcode', 'phenotype', 'conc'])\n",
    "controls_bc = controls.barcode.values\n",
    "#lib10_cntrl_clr = lib10_clr.loc[controls_bc]\n",
    "#lib10_cntrl_vst = lib10_vst.loc[controls_bc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_cntrs = controls[controls.phenotype == 'wt'].reset_index()['barcode'].values\n",
    "lib10_wt_cntrl_clr = lib10_cntrl_clr.loc[wt_cntrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# sns.set(font_scale=.8)\n",
    "# lut = dict(zip(lib10_sdata.mouse.unique(), sns.color_palette(\"hls\", 19)))\n",
    "# row_colors = lib10_sdata.mouse.map(lut)\n",
    "# #controls = controls.set_index('barcode')\n",
    "# lut2 = dict(zip(controls.phenotype.unique(), sns.color_palette(\"hls\", 5)))\n",
    "# col_colors = controls.phenotype.map(lut2)\n",
    "\n",
    "# g = sns.clustermap(lib10_cntrl_vst.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "#                row_colors=row_colors,col_cluster=False, col_colors=col_colors, dendrogram_ratio=(0.5,0.2), cmap =\"vlag\")\n",
    "\n",
    "\n",
    "# # Creating Legend\n",
    "# #function_legend = [mpl.patches.Patch(color=c, label=l) for l,c in function_to_color.items()]\n",
    "# pg_legend = [mpl.patches.Patch(color=c, label=l) for l,c in lut2.items()]\n",
    "\n",
    "# # Displaying function legend\n",
    "# l2 = g.ax_heatmap.legend(handles=pg_legend, bbox_to_anchor=(-0.5,1.2), frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.mouse.unique(), sns.color_palette(\"hls\", 19)))\n",
    "row_colors = lib10_sdata.mouse.map(lut)\n",
    "#controls = controls.set_index('barcode')\n",
    "lut2 = dict(zip(controls.phenotype.unique(), sns.color_palette(\"hls\", 5)))\n",
    "col_colors = controls.phenotype.map(lut2)\n",
    "\n",
    "g = sns.clustermap(lib10_cntrl_clr.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors,col_cluster=False, col_colors=col_colors, dendrogram_ratio=(0.5,0.2), cmap =\"vlag\")\n",
    "\n",
    "\n",
    "# Creating Legend\n",
    "#function_legend = [mpl.patches.Patch(color=c, label=l) for l,c in function_to_color.items()]\n",
    "pg_legend = [mpl.patches.Patch(color=c, label=l) for l,c in lut2.items()]\n",
    "\n",
    "# Displaying function legend\n",
    "l2 = g.ax_heatmap.legend(handles=pg_legend, bbox_to_anchor=(-0.5,1.2), frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.mouse.unique(), sns.color_palette(\"hls\", 19)))\n",
    "row_colors = lib10_sdata.mouse.map(lut)\n",
    "#controls = controls.set_index('barcode')\n",
    "#lut2 = dict(zip(controls.phenotype.unique(), sns.color_palette(\"hls\", 5)))\n",
    "#col_colors = controls.phenotype.map(lut2)\n",
    "\n",
    "g = sns.clustermap(lib10_wt_cntrl_clr.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors,col_cluster=False, col_colors=col_colors, dendrogram_ratio=(0.5,0.2), cmap =\"vlag\")\n",
    "\n",
    "\n",
    "# Creating Legend\n",
    "#function_legend = [mpl.patches.Patch(color=c, label=l) for l,c in function_to_color.items()]\n",
    "pg_legend = [mpl.patches.Patch(color=c, label=l) for l,c in lut2.items()]\n",
    "\n",
    "# Displaying function legend\n",
    "l2 = g.ax_heatmap.legend(handles=pg_legend, bbox_to_anchor=(-0.5,1.2), frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib10_sdata.day.unique(), sns.color_palette(\"hls\", 5)))\n",
    "row_colors = lib10_sdata.day.map(lut)\n",
    "#controls = controls.set_index('barcode')\n",
    "lut2 = dict(zip(controls.phenotype.unique(), sns.color_palette(\"hls\", 5)))\n",
    "col_colors = controls.phenotype.map(lut2)\n",
    "\n",
    "g = sns.clustermap(lib10_cntrl_clr.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors,col_cluster=False, col_colors=col_colors, dendrogram_ratio=(0.5,0.2), cmap =\"vlag\")\n",
    "\n",
    "\n",
    "# Creating Legend\n",
    "#function_legend = [mpl.patches.Patch(color=c, label=l) for l,c in function_to_color.items()]\n",
    "pg_legend = [mpl.patches.Patch(color=c, label=l) for l,c in lut2.items()]\n",
    "\n",
    "# Displaying function legend\n",
    "l2 = g.ax_heatmap.legend(handles=pg_legend, bbox_to_anchor=(-0.5,1.2), frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_wt = (cnt_df[(cnt_df.phenotype == 'wt')&(cnt_df.library == 'library_10_2')]\n",
    "            .copy()[['barcode','cnt', 'conc', 'sampleName', 'experiment', 'dnaid', 'sampleID', 'day', 'mouse']])\n",
    "\n",
    "lib10_wt['logcnt'] = np.log2(lib10_wt['cnt'])\n",
    "# corr_df = lib14_wt.groupby(['experiment','sampleID'])[['conc', 'logcnt']].corr().reset_index()\n",
    "# corr_df = corr_df[corr_df['level_2'] == 'conc'].drop(['level_2', 'conc'], axis=1)\n",
    "# corr_df.columns = ['experiment','sampleID', 'R']\n",
    "# corr_df['Rlab'] = corr_df.R.apply(lambda x: f'R = {round(x, 2)}')\n",
    "# lib14_wt = lib14_wt.merge(corr_df, on=['experiment', 'sampleID'])\n",
    "\n",
    "lib10_wt.experiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib10_wt[lib10_wt.experiment =='TV4592A']\n",
    "x = lib10_wt.day.nunique()\n",
    "y = lib10_wt.mouse.nunique()\n",
    "p9.options.figure_size = (x*3, y*3)\n",
    "g = (p9.ggplot(data, p9.aes(x='conc', y='cnt'))\n",
    "  + p9.geom_point()\n",
    "  + p9.geom_smooth(method=\"lm\")\n",
    "  + p9.theme_classic()\n",
    "  + p9.theme(text=p9.element_text(size=14),\n",
    "             axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    "    #+ p9.geom_text(p9.aes(label='Rlab', x=0.0001, y=.1))\n",
    "  + p9.ylab(\"Count\")\n",
    "  + p9.xlab(\"Expected Abundance\")\n",
    "  + p9.scale_y_log10()\n",
    "  + p9.scale_x_log10()\n",
    "  + p9.facet_grid('mouse~day'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib10_wt[lib10_wt.experiment =='TV5563A']\n",
    "x = lib10_wt.day.nunique()\n",
    "y = lib10_wt.mouse.nunique()\n",
    "p9.options.figure_size = (x*3, y*3)\n",
    "g = (p9.ggplot(data, p9.aes(x='conc', y='cnt'))\n",
    "  + p9.geom_point()\n",
    "  + p9.geom_smooth(method=\"lm\")\n",
    "  + p9.theme_classic()\n",
    "  + p9.theme(text=p9.element_text(size=14),\n",
    "             axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    "    #+ p9.geom_text(p9.aes(label='Rlab', x=0.0001, y=.1))\n",
    "  + p9.ylab(\"Count\")\n",
    "  + p9.xlab(\"Expected Abundance\")\n",
    "  + p9.scale_y_log10()\n",
    "  + p9.scale_x_log10()\n",
    "  + p9.facet_grid('mouse~day'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib10_wt[lib10_wt.experiment =='TV5585A']\n",
    "x = lib10_wt.day.nunique()\n",
    "y = lib10_wt.mouse.nunique()\n",
    "p9.options.figure_size = (x*3, y*2.5)\n",
    "g = (p9.ggplot(data, p9.aes(x='conc', y='cnt'))\n",
    "  + p9.geom_point()\n",
    "  + p9.geom_smooth(method=\"lm\")\n",
    "  + p9.theme_classic()\n",
    "  + p9.theme(text=p9.element_text(size=14),\n",
    "             axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    "    #+ p9.geom_text(p9.aes(label='Rlab', x=0.0001, y=.1))\n",
    "  + p9.ylab(\"Count\")\n",
    "  + p9.xlab(\"Expected Abundance\")\n",
    "  + p9.scale_y_log10()\n",
    "  + p9.scale_x_log10()\n",
    "  + p9.facet_grid('mouse~day'))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-partner",
   "metadata": {},
   "source": [
    "# Library 14_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-profit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib14_cnt = cnt_df[cnt_df.library == 'library_14_2'].copy()\n",
    "lib14_cnt = lib14_cnt[['barcode', 'sampleID', 'experiment', 'mouse', 'day', 'tissue', 'dnaid', 'cnt']].drop_duplicates()\n",
    "lib14_cnt['sampleID'] = lib14_cnt['sampleID']+ \"_\" + lib14_cnt['dnaid'] + '_' + lib14_cnt['experiment']\n",
    "lib14_sdata = lib14_cnt[['sampleID', 'mouse', 'day', 'tissue', 'dnaid', 'experiment']].set_index('sampleID').drop_duplicates()\n",
    "lib14_cnt = lib14_cnt.pivot(index='barcode', columns='sampleID', values='cnt')\n",
    "lib14_cnt = lib14_cnt.fillna(0)\n",
    "columns_to_filter = [f for f in lib14_cnt.columns if 'inoculum' in f]\n",
    "lib14_cnt = lib14_cnt[(lib14_cnt[columns_to_filter] >= 1000).all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-agency",
   "metadata": {},
   "source": [
    "## VST Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf14 = lib14_sdata\n",
    "edf14 = lib14_cnt[list(sdf14.index)]\n",
    "sdf14.to_csv(Path(root)/results/'lib14_sdf.csv')\n",
    "edf14.to_csv(Path(root)/results/'lib14_edf.csv')\n",
    "# Run DESeq2\n",
    "lib14_vst = pd.read_csv(Path(root)/results/'lib14_vsd.csv').rename({'Unnamed: 0':'barcode'}, axis=1).set_index('barcode')\n",
    "pDf_vst, pc1_vst, pc2_vst = find_pc1_pc2(lib14_vst, lib14_sdata)\n",
    "\n",
    "plotPCA(pDf_vst, pc1_vst, pc2_vst, colorby='experiment', nameby='day', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib10_sdata.mouse.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-reply",
   "metadata": {},
   "source": [
    "## CLR Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skbio.stats.composition import clr\n",
    "lib14_clr = lib14_cnt.apply(lambda x: clr(x+1))\n",
    "\n",
    "pDf_clr, pc1_clr, pc2_clr = find_pc1_pc2(lib14_clr, lib14_sdata)\n",
    "\n",
    "plotPCA(pDf_clr, pc1_clr, pc2_clr, colorby='experiment', nameby='mouse', col=list(sns.color_palette()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib14_sdata.mouse.unique(), sns.color_palette(\"hls\", 14)))\n",
    "row_colors = lib14_sdata.mouse.map(lut)\n",
    "\n",
    "sns.clustermap(lib14_clr.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors, dendrogram_ratio=(0.5,0.2), cmap='vlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib14_sdata.day.unique(), sns.color_palette(\"hls\", 6)))\n",
    "row_colors = lib14_sdata.day.map(lut)\n",
    "\n",
    "sns.clustermap(lib14_clr.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors, dendrogram_ratio=(0.5,0.2), cmap='vlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=.8)\n",
    "lut = dict(zip(lib14_sdata.experiment.unique(), sns.color_palette(\"hls\", 3)))\n",
    "row_colors = lib14_sdata.experiment.map(lut)\n",
    "\n",
    "sns.clustermap(lib14_clr.T, method='average', metric='correlation', figsize=(20, 20), \n",
    "               row_colors=row_colors, dendrogram_ratio=(0.5,0.2), cmap='vlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib14_wt = (cnt_df[(cnt_df.phenotype == 'wt')&(cnt_df.library == 'library_14_2')]\n",
    "            .copy()[['barcode','cnt', 'conc', 'sampleName', 'experiment', 'dnaid', 'sampleID', 'day', 'mouse']])\n",
    "\n",
    "lib14_wt['logcnt'] = np.log2(lib14_wt['cnt'])\n",
    "corr_df = lib14_wt.groupby(['experiment','sampleID'])[['conc', 'logcnt']].corr().reset_index()\n",
    "corr_df = corr_df[corr_df['level_2'] == 'conc'].drop(['level_2', 'conc'], axis=1)\n",
    "corr_df.columns = ['experiment','sampleID', 'R']\n",
    "corr_df['Rlab'] = corr_df.R.apply(lambda x: f'R = {round(x, 2)}')\n",
    "lib14_wt = lib14_wt.merge(corr_df, on=['experiment', 'sampleID'])\n",
    "\n",
    "lib14_wt.experiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib14_wt[lib14_wt.experiment =='TV4592B']\n",
    "x = lib14_wt.day.nunique()\n",
    "y = lib14_wt.mouse.nunique()\n",
    "p9.options.figure_size = (x*3, y*3)\n",
    "g = (p9.ggplot(data, p9.aes(x='conc', y='cnt'))\n",
    "  + p9.geom_point()\n",
    "  + p9.geom_smooth(method=\"lm\")\n",
    "  + p9.theme_classic()\n",
    "  + p9.theme(text=p9.element_text(size=14),\n",
    "             axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    "    #+ p9.geom_text(p9.aes(label='Rlab', x=0.0001, y=.1))\n",
    "  + p9.ylab(\"Count\")\n",
    "  + p9.xlab(\"Expected Abundance\")\n",
    "  + p9.scale_y_log10()\n",
    "  + p9.scale_x_log10()\n",
    "  + p9.facet_grid('mouse~day'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib14_wt[lib14_wt.experiment =='TV5490C']\n",
    "x = lib14_wt.day.nunique()\n",
    "y = lib14_wt.mouse.nunique()\n",
    "p9.options.figure_size = (x*3, y*3)\n",
    "g = (p9.ggplot(data, p9.aes(x='conc', y='cnt'))\n",
    "  + p9.geom_point()\n",
    "  + p9.geom_smooth(method=\"lm\")\n",
    "  + p9.theme_classic()\n",
    "  + p9.theme(text=p9.element_text(size=14),\n",
    "             axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    "    #+ p9.geom_text(p9.aes(label='Rlab', x=0.0001, y=.1))\n",
    "  + p9.ylab(\"Count\")\n",
    "  + p9.xlab(\"Expected Abundance\")\n",
    "  + p9.scale_y_log10()\n",
    "  + p9.scale_x_log10()\n",
    "  + p9.facet_grid('mouse~day'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lib14_wt[lib14_wt.experiment =='TV5536B']\n",
    "x = lib14_wt.day.nunique()\n",
    "y = lib14_wt.mouse.nunique()\n",
    "p9.options.figure_size = (x*3, y*3)\n",
    "g = (p9.ggplot(data, p9.aes(x='conc', y='cnt'))\n",
    "  + p9.geom_point()\n",
    "  + p9.geom_smooth(method=\"lm\")\n",
    "  + p9.theme_classic()\n",
    "  + p9.theme(text=p9.element_text(size=14),\n",
    "             axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    "    #+ p9.geom_text(p9.aes(label='Rlab', x=0.0001, y=.1))\n",
    "  + p9.ylab(\"Count\")\n",
    "  + p9.xlab(\"Expected Abundance\")\n",
    "  + p9.scale_y_log10()\n",
    "  + p9.scale_x_log10()\n",
    "  + p9.facet_grid('mouse~day'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(p9.aes(x='conc', y='cnt', ),data=lib14_wt)\n",
    "+ p9.geom_point()\n",
    "+p9.facet_grid('day ~ mouse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib14_cnt.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-store",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Get genes that are present in all inoculum samples. \n",
    "    - Nubmer of samples is 10, choose genes that have sampleName.nunique == 10\n",
    "- For each gene, if # of barcodes > 1, \n",
    "    - pick barcode that is present in all samples\n",
    "    - pick a barcode with max count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps\n",
    "\n",
    "test = cnt_df[cnt_df.library == 'library_14_2']\n",
    "test = test[test.day == 'd0']\n",
    "test.sampleName.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = test.groupby(['ShortName']).agg({'sampleName':['nunique']}).reset_index()\n",
    "t2.columns = ['gene', 'num_samples']\n",
    "t2 = t2[t2.num_samples == 10].gene.values\n",
    "test = test[test.ShortName.isin(t2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-farmer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_bc_per_gene = test.groupby('ShortName').barcode.nunique().reset_index()\n",
    "m_bc_per_gene = one_bc_per_gene[one_bc_per_gene.barcode > 1].ShortName.values\n",
    "one_bc_per_gene = one_bc_per_gene[one_bc_per_gene.barcode == 1].ShortName.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m_bc_per_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one_bc_per_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.ShortName.isin(m_bc_per_gene)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sample(10)[['barcode', 'cnt', 'ShortName', 'sampleName', 'experiment', 'sampleID', 'dnaid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.groupby(['ShortName', 'barcode']).sampleName.nunique().reset_index()\n",
    "x = x[x.sampleName == 10].barcode.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.barcode.isin(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(['ShortName', 'barcode']).agg({'cnt':['median']})\n",
    "# pick the one with the largest mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.ShortName == 'ytfL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-button",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
